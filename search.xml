<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ELK个人实践]]></title>
    <url>%2F2019%2F10%2F24%2FELK%E4%B8%AA%E4%BA%BA%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[ELK Stack简介ELK 不是一款软件，而是 Elasticsearch、Logstash 和 Kibana 三种软件产品的首字母缩写。这三者都是开源软件，通常配合使用，而且又先后归于 Elastic.co 公司名下，所以被简称为 ELK Stack。根据 Google Trend 的信息显示，ELK Stack 已经成为目前最流行的集中式日志解决方案。 1. Elasticsearch - 为了搜索Elasticsearch是一个基于Apache Lucene(TM)的开源搜索引擎。无论在开源还是专有领域，Lucene可以被认为是迄今为止最先进、性能最好的、功能最全的搜索引擎库。 但是，Lucene只是一个库。想要使用它，你必须使用Java来作为开发语言并将其直接集成到你的应用中，更糟糕的是，Lucene非常复杂，你需要深入了解检索的相关知识来理解它是如何工作的。 Elasticsearch也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的RESTful API来隐藏Lucene的复杂性，从而让全文搜索变得简单。 不过，Elasticsearch不仅仅是Lucene和全文搜索，我们还能这样去描述它： 分布式的实时文件存储，每个字段都被索引并可被搜索 分布式的实时分析搜索引擎 可以扩展到上百台服务器，处理PB级结构化或非结构化数据 而且，所有的这些功能被集成到一个服务里面，你的应用可以通过简单的RESTful API、各种语言的客户端甚至命令行与之交互。 上手Elasticsearch非常容易。它提供了许多合理的缺省值，并对初学者隐藏了复杂的搜索引擎理论。它开箱即用（安装即可使用），只需很少的学习既可在生产环境中使用。 Elasticsearch在Apache 2 license下许可使用，可以免费下载、使用和修改。 存储数据的行为就叫做索引(indexing)在Elasticsearch中，文档归属于一种类型(type)，而这些类型存在于索引(index)中，我们可以画一些简单的对比图来类比传统关系型数据库： 12Relational DB -&gt; Databases -&gt; Tables -&gt; Rows -&gt; ColumnsElasticsearch -&gt; Indices -&gt; Types -&gt; Documents -&gt; Fields Elasticsearch集群可以包含多个索引(indices)（数据库），每一个索引可以包含多个类型(types)（表），每一个类型包含多个文档(documents)（行），然后每个文档包含多个字段(Fields)（列）。 12345678910小贴士：多年前，一个叫做Shay Banon的刚结婚不久的失业开发者，由于妻子要去伦敦学习厨师，他便跟着也去了。在他找工作的过程中，为了给妻子构建一个食谱的搜索引擎，他开始构建一个早期版本的Lucene。直接基于Lucene工作会比较困难，所以Shay开始抽象Lucene代码以便Java程序员可以在应用中添加搜索功能。他发布了他的第一个开源项目，叫做“Compass”。后来Shay找到一份工作，这份工作处在高性能和内存数据网格的分布式环境中，因此高性能的、实时的、分布式的搜索引擎也是理所当然需要的。然后他决定重写Compass库使其成为一个独立的服务叫做Elasticsearch。第一个公开版本出现在2010年2月，在那之后Elasticsearch已经成为Github上最受欢迎的项目之一，代码贡献者超过300人。一家主营Elasticsearch的公司就此成立，他们一边提供商业支持一边开发新功能，不过Elasticsearch将永远开源且对所有人可用。Shay的妻子依旧等待着她的食谱搜索…… 2. Logstash - 数据收集Logstash是一款数据收集引擎。它支持动态的从各种数据源搜集数据，并对数据进行过滤、分析、丰富、统一格式等操作，然后存储到用户指定的位置； Logstash 项目诞生于 2009 年 8 月 2 日。其作者是世界著名的运维工程师乔丹西塞(JordanSissel)（发布过非常棒的软件打包工具 fpm） scribed 在 2011 年进入半死不活的状态，大大激发了其他各种开源日志收集处理框架的蓬勃发展，Logstash 也从 2011 年开始进入 commit 密集期并延续至今。 2013 年，Logstash 被 Elasticsearch 公司收购，ELK stack 正式成为官方用语。Elasticsearch 本身 也是近两年最受关注的大数据项目之一，三次融资已经超过一亿美元。在 Elasticsearch 开发人员的共同努力下，Logstash 的发布机制，插件架构也愈发科学和合理。 123小贴士：elasticsearch 项目开始于 2010 年，其实比 logstash 还晚； 3. Kibana - 数据展示Kibana 是一款开源的数据分析和可视化平台，它是 Elastic Stack 成员之一，设计用于和 Elasticsearch 协作。您可以使用 Kibana 对 Elasticsearch 索引中的数据进行搜索、查看、交互操作。您可以很方便的利用图表、表格及地图对数据进行多元化的分析和呈现。 Kibana 可以使大数据通俗易懂。它很简单，基于浏览器的界面便于您快速创建和分享动态数据仪表板来追踪 Elasticsearch 的实时数据变化。 搭建 Kibana 非常简单。您可以分分钟完成 Kibana 的安装并开始探索 Elasticsearch 的索引数据 — 没有代码、不需要额外的基础设施。 4. Filebeat - 数据搜集ELK 协议栈的新成员，一个轻量级开源日志文件数据搜集器，基于 Logstash-Forwarder 源代码开发，是对它的替代。在需要采集日志数据的 server 上安装 Filebeat，并指定日志目录或日志文件后，Filebeat 就能读取数据，迅速发送到 Logstash 进行解析，亦或直接发送到 Elasticsearch 进行集中式存储和分析。 ELK 常用架构及使用场景介绍最简单架构在这种架构中，只有一个 Logstash、Elasticsearch 和 Kibana 实例。Logstash 通过输入插件从多种数据源（比如日志文件、标准输入 Stdin 等）获取数据，再经过滤插件加工数据，然后经 Elasticsearch 输出插件输出到 Elasticsearch，通过 Kibana 展示。详见图 1。 图 1. 最简单架构 这种架构非常简单，使用场景也有限。初学者可以搭建这个架构，了解 ELK 如何工作。 Logstash 作为日志搜集器这种架构是对上面架构的扩展，把一个 Logstash 数据搜集节点扩展到多个，分布于多台机器，将解析好的数据发送到 Elasticsearch server 进行存储，最后在 Kibana 查询、生成日志报表等。详见图 2。 图 2. Logstash 作为日志搜索器 这种结构因为需要在各个服务器上部署 Logstash，而它比较消耗 CPU 和内存资源，所以比较适合计算资源丰富的服务器，否则容易造成服务器性能下降，甚至可能导致无法正常工作。 Beats 作为日志搜集器这种架构引入 Beats 作为日志搜集器。目前 Beats 包括四种： Packetbeat（搜集网络流量数据）； Topbeat（搜集系统、进程和文件系统级别的 CPU 和内存使用情况等数据）； Filebeat（搜集文件数据）； Winlogbeat（搜集 Windows 事件日志数据）。 Beats 将搜集到的数据发送到 Logstash，经 Logstash 解析、过滤后，将其发送到 Elasticsearch 存储，并由 Kibana 呈现给用户。详见图 3。 图 3. Beats 作为日志搜集器 这种架构解决了 Logstash 在各服务器节点上占用系统资源高的问题。相比 Logstash，Beats 所占系统的 CPU 和内存几乎可以忽略不计。另外，Beats 和 Logstash 之间支持 SSL/TLS 加密传输，客户端和服务器双向认证，保证了通信安全。 因此这种架构适合对数据安全性要求较高，同时各服务器性能比较敏感的场景。 引入消息队列机制的架构到笔者整理本文时，Beats 还不支持输出到消息队列，所以在消息队列前后两端只能是 Logstash 实例。这种架构使用 Logstash 从各个数据源搜集数据，然后经消息队列输出插件输出到消息队列中。目前 Logstash 支持 Kafka、Redis、RabbitMQ 等常见消息队列。然后 Logstash 通过消息队列输入插件从队列中获取数据，分析过滤后经输出插件发送到 Elasticsearch，最后通过 Kibana 展示。详见图 4。 图 4. 引入消息队列机制的架构 这种架构适合于日志规模比较庞大的情况。但由于 Logstash 日志解析节点和 Elasticsearch 的负荷比较重，可将他们配置为集群模式，以分担负荷。引入消息队列，均衡了网络传输，从而降低了网络闭塞，尤其是丢失数据的可能性，但依然存在 Logstash 占用系统资源过多的问题。 基于 Filebeat 架构前面提到 Filebeat 已经完全替代了 Logstash-Forwarder 成为新一代的日志采集器，同时鉴于它轻量、安全等特点，越来越多人开始使用它。这个章节将详细讲解如何部署基于 Filebeat 的 ELK 集中式日志解决方案，具体架构见图 5。 图 5. 基于 Filebeat 的 ELK 集群架构 因为免费的 ELK 没有任何安全机制，所以这里使用了 Nginx 作反向代理，避免用户直接访问 Kibana 服务器。加上配置 Nginx 实现简单的用户认证，一定程度上提高安全性。另外，Nginx 本身具有负载均衡的作用，能够提高系统访问性能。 Docker-compose 搭建ELK1. docker-compose.yml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106version: &apos;2.2&apos;services: es-master: image: elasticsearch:7.4.0 container_name: es-master environment: - node.name=es-master - discovery.seed_hosts=es02 - cluster.initial_master_nodes=es-master,es02 - cluster.name=docker-cluster - bootstrap.memory_lock=true - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; ulimits: memlock: soft: -1 hard: -1 volumes: - esdata01:/usr/share/elasticsearch/data ports: - 9200:9200 networks: - esnet es02: image: elasticsearch:7.4.0 container_name: es02 environment: - node.name=es02 - discovery.seed_hosts=es-master - cluster.initial_master_nodes=es-master,es02 - cluster.name=docker-cluster - bootstrap.memory_lock=true - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; ulimits: memlock: soft: -1 hard: -1 volumes: - esdata02:/usr/share/elasticsearch/data networks: - esnet elastichd: container_name: elastichd image: containerize/elastichd ports: - 9800:9800 networks: - esnet kibana: container_name: kibana hostname: kibana image: kibana:7.4.0 ports: - 5601:5601 volumes: - ./kibana/conf/kibana.yml:/usr/share/kibana/config/kibana.yml environment: - elasticsearch.hosts=http://es-master:9200 networks: - esnet filebeat: # 容器名称 container_name: filebeat # 主机名称 hostname: filebeat # 镜像 image: docker.elastic.co/beats/filebeat:7.4.0 # 持久化挂载 volumes: - ./filebeat/conf/filebeat.yml:/usr/share/filebeat/filebeat.yml # 映射到容器中[作为数据源] - ./logs:/home/project/spring-boot-elasticsearch/logs - ./filebeat/logs:/usr/share/filebeat/logs - ./filebeat/data:/usr/share/filebeat/data # 将指定容器连接到当前连接，可以设置别名，避免ip方式导致的容器重启动态改变的无法连接情况 links: - logstash networks: - esnet logstash: container_name: logstash hostname: logstash image: logstash:7.4.0 volumes: # 映射到容器中 - ./logstash/conf/logstash-filebeat.conf:/usr/share/logstash/pipeline/logstash.conf - ./logstash/conf/logstash.yml:/usr/share/logstash/config/logstash.yml - ./logstash/logs:/usr/share/logstash/logs environment: - elasticsearch.hosts=http://es-master:9200 ports: - 5044:5044 networks: - esnetvolumes: esdata01: driver: local esdata02: driver: localnetworks: esnet: 2. logstash-filebeat.conf1234567891011121314151617181920212223242526272829input &#123; # 来源beats beats &#123; # 端口 port =&gt; &quot;5044&quot; # ssl配置 # ssl =&gt; true # ssl_certificate_authorities =&gt; [&quot;/etc/pki/tls/certs/filebeat.crt&quot;] # ssl_certificate =&gt; &quot;/etc/pki/tls/certs/logstash.crt&quot; # ssl_key =&gt; &quot;/etc/pki/tls/private/logstash.key&quot; # ssl_verify_mode =&gt; &quot;force_peer&quot; &#125;&#125;# 分析、过滤插件，可以多个filter &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;COMBINEDAPACHELOG&#125;&quot;&#125; &#125; geoip &#123; source =&gt; &quot;clientip&quot; &#125;&#125;output &#123; # 选择elasticsearch elasticsearch &#123; hosts =&gt; [&quot;http://es-master:9200&quot;] index =&gt; &quot;%&#123;[@metadata][beat]&#125;-%&#123;[@metadata][version]&#125;-%&#123;+YYYY.MM.dd&#125;&quot; &#125;&#125; 3. logstash.yml123http.host: &quot;0.0.0.0&quot;xpack.monitoring.elasticsearch.hosts: [ &quot;http://es-master:9200&quot; ]xpack.monitoring.enabled: true 4. filebeat.yml1234567891011121314151617181920212223242526272829303132333435363738394041filebeat.inputs:- type: log enabled: true paths: # 当前目录下的所有.log文件 - /home/project/spring-boot-elasticsearch/logs/*.log # 多个文件夹 # prospectors: # - paths: # - /home/project/spring-boot-elasticsearch/logs/*.log # - paths: # - /home/project/spring-boot-elasticsearch/logs/*.log multiline.pattern: ^\[ multiline.negate: true multiline.match: afterfilebeat.config.modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: falsesetup.template.settings: index.number_of_shards: 1setup.dashboards.enabled: falsesetup.kibana: host: &quot;http://kibana:5601&quot;# 不直接传输至ES#output.elasticsearch:# hosts: [&quot;http://es-master:9200&quot;]# index: &quot;filebeat-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;&quot;output.logstash: hosts: [&quot;logstash:5044&quot;]processors: - add_host_metadata: ~ - add_cloud_metadata: ~ 5. kibana.yml12345678# 服务端口server.port: 5601# 服务IPserver.host: &quot;0.0.0.0&quot;# ESelasticsearch.hosts: [&quot;http://es-master:9200&quot;]# 汉化i18n.locale: &quot;zh-CN&quot; 遇到的问题 cpu跑满 1docker加配置 data文件夹挂载 1清理data文件夹 es status 406 error 123456789101112131415curl -X POST http://localhost:9200/tracy/fulltext/_mapping -d&apos;&#123; &quot;properties&quot;: &#123; &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_max_word&quot; &#125; &#125; &#125;&apos;6.0版本以后-H &quot;Content-Type: application/json&quot; es单点模式索引未分配 1改成集群模式可破]]></content>
  </entry>
  <entry>
    <title><![CDATA[nginx常见配置]]></title>
    <url>%2F2018%2F09%2F21%2Fnginx%E5%B8%B8%E8%A7%81%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Nginx常用配置包括：动静分离、缓存设置、负载均衡、反向代理、还有虚拟主机功能。 Nginx启动和关闭123/usr/local/bin/nginx # 启动/usr/local/bin/nginx -s reload #平滑重启/usr/local/etc/nginx/nginx.cnf #配置文件。 配置文件详解大致的分块： 1234567891011121314151617181920212223main # 全局设置events &#123; # Nginx工作模式 ....&#125;http &#123; # http设置 .... upstream myproject &#123; # 负载均衡服务器设置 ..... &#125; server &#123; # 主机设置 .... location &#123; # URL匹配 .... &#125; &#125; server &#123; .... location &#123; .... &#125; &#125; ....&#125; main模块下面是一个main区域，它是一个全局的设置： 12345user nobody nobody;worker_processes 2;error_log /usr/local/var/log/nginx/error.log notice;pid /usr/local/var/run/nginx/nginx.pid;worker_rlimit_nofile 1024; user 来指定Nginx Worker进程运行用户以及用户组，默认由nobody账号运行。 worker_processes 来指定了Nginx要开启的子进程数。每个Nginx进程平均耗费10M~12M内存。根据经验，一般指定1个进程就足够了，如果是多核CPU，建议指定和CPU的数量一样的进程数即可。我这里写2，那么就会开启2个子进程，总共3个进程。 error_log 来定义全局错误日志文件。日志输出级别有debug、info、notice、warn、error、crit可供选择，其中，debug输出日志最为最详细，而crit输出日志最少。 pid 来指定进程id的存储文件位置。 worker_rlimit_nofile 来指定一个nginx进程可以打开的最多文件描述符数目，这里是65535，需要使用命令“ulimit -n 65535”来设置。 events模块events模块来用指定nginx的工作模式和工作模式及连接数上限，一般是这样： 1234events &#123; use kqueue; #mac平台 worker_connections 1024;&#125; use 用来指定Nginx的工作模式。Nginx支持的工作模式有select、poll、kqueue、epoll、rtsig和/dev/poll。其中select和poll都是标准的工作模式，kqueue和epoll是高效的工作模式，不同的是epoll用在Linux平台上，而kqueue用在BSD系统中，因为Mac基于BSD,所以Mac也得用这个模式，对于Linux系统，epoll工作模式是首选。 worker_connections 用于定义Nginx每个进程的最大连接数，即接收前端的最大请求数，默认是1024。最大客户端连接数由worker_processes和worker_connections决定，即Max_clients = worker_processes worker_connections，在作为反向代理时，Max_clients变为：Max_clients = worker_processes worker_connections / 4。 进程的最大连接数受Linux系统进程的最大打开文件数限制，在执行操作系统命令“ulimit -n 65536”后worker_connections的设置才能生效。 http模块http模块可以说是最核心的模块了，它负责HTTP服务器相关属性的配置，它里面的server和upstream子模块，至关重要，等到反向代理和负载均衡以及虚拟目录等会仔细说。 12345678910111213141516171819http &#123; include mime.types; default_type application/octet-stream; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log /usr/local/var/log/nginx/access.log main; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 10; #gzip on; upstream myproject &#123; ..... &#125; server &#123; .... &#125;&#125; include 用来设定文件的mime类型,类型在配置文件目录下的mime.type文件定义，来告诉nginx来识别文件类型。 default_type 设定了默认的类型为二进制流，也就是当文件类型未定义时使用这种方式，例如在没有配置asp的locate 环境时，Nginx是不予解析的，此时，用浏览器访问asp文件就会出现下载窗口了。 log_format 用于设置日志的格式，和记录哪些参数，这里设置为main，刚好用于access_log来纪录这种类型。 main的类型日志如下：也可以增删部分参数。 127.0.0.1 - - [21/Apr/2015:18:09:54 +0800] “GET /index.php HTTP/1.1” 200 87151 “-“ “Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.76 Safari/537.36” access_log 用来纪录每次的访问日志的文件地址，后面的main是日志的格式样式，对应于log_format的main。 sendfile 用于开启高效文件传输模式。将tcp_nopush和tcp_nodelay两个指令设置为on用于防止网络阻塞。 keepalive_timeout 设置客户端连接保持活动的超时时间。在超过这个时间之后，服务器会关闭该连接。 server模块server模块是http的子模块，它用来定一个虚拟主机，我们先讲最基本的配置，这些在后面再讲。我们看一下一个简单的server是如何做的？ 1234567891011server &#123; listen 8080; server_name localhost 192.168.12.10 www.yangyi.com; # 全局定义，如果都是这一个目录，这样定义最简单。 root /Users/yangyi/www; index index.php index.html index.htm; charset utf-8; access_log usr/local/var/log/host.access.log main; error_log usr/local/var/log/host.error.log error; ....&#125; server 标志定义虚拟主机开始。 listen 用于指定虚拟主机的服务端口。 server_name 用来指定IP地址或者域名，多个域名之间用空格分开。 root 表示在这整个server虚拟主机内，全部的root web根目录。注意要和locate {}下面定义的区分开来。 index 全局定义访问的默认首页地址。注意要和locate {}下面定义的区分开来。 charset 用于设置网页的默认编码格式。 access_log 用来指定此虚拟主机的访问日志存放路径，最后的main用于指定访问日志的输出格式。 location模块location模块是nginx中用的最多的，也是最重要的模块了，什么负载均衡啊、反向代理啊、虚拟域名啊都与它相关。 location根据它字面意思就知道是来定位的，定位URL，解析URL，所以，它也提供了强大的正则匹配功能，也支持条件判断匹配，用户可以通过location指令实现Nginx对动、静态网页进行过滤处理。像我们的php环境搭建就是用到了它。 我们先来看这个，设定默认首页和虚拟机目录 1234location / &#123; root /Users/yangyi/www; index index.php index.html index.htm;&#125; location / 表示匹配访问根目录。 root 指令用于指定访问根目录时，虚拟主机的web目录，这个目录可以是相对路径（相对路径是相对于nginx的安装目录）。也可以是绝对路径。 index 用于设定我们只输入域名后访问的默认首页地址，有个先后顺序：index.php index.html index.htm，如果没有开启目录浏览权限，又找不到这些默认首页，就会报403错误。 location 还有一种方式就是正则匹配 下面这个例子是运用正则匹配来链接php。我们之前搭建环境也是这样做： 123456location ~ \.php$ &#123; root /Users/yangyi/www; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf;&#125; .php$ 熟悉正则的我们直到，这是匹配.php结尾的URL，用来解析php文件。里面的root也是一样，用来表示虚拟主机的根目录。 fastcgi_pass 链接的是php-fpm的地址。其他几个参数我们以后再说。 location 还有其他用法，等讲到实例的时候，再看吧。 upstream模块upstream 模块负责负载均衡模块，通过一个简单的调度算法来实现客户端IP到后端服务器的负载均衡。先学习怎么用，具体的使用实例以后再说。 1234567upstream iyangyi.com&#123; ip_hash; server 192.168.12.1:80; server 192.168.12.2:80 down; server 192.168.12.3:8080 max_fails=3 fail_timeout=20s; server 192.168.12.4:8080;&#125; 在上面的例子中，通过upstream指令指定了一个负载均衡器的名称iyangyi.com。这个名称可以任意指定，在后面需要的地方直接调用即可。里面是ip_hash这是其中的一种负载均衡调度算法，下面会着重介绍。紧接着就是各种服务器了。用server关键字表识，后面接ip。 Nginx的负载均衡模块目前支持4种调度算法： weight 轮询（默认）。每个请求按时间顺序逐一分配到不同的后端服务器，如果后端某台服务器宕机，故障系统被自动剔除，使用户访问不受影响。weight。指定轮询权值，weight值越大，分配到的访问机率越高，主要用于后端每个服务器性能不均的情况下。 ip_hash。每个请求按访问IP的hash结果分配，这样来自同一个IP的访客固定访问一个后端服务器，有效解决了动态网页存在的session共享问题。 fair（第三方）。比上面两个更加智能的负载均衡算法。此种算法可以依据页面大小和加载时间长短智能地进行负载均衡，也就是根据后端服务器的响应时间来分配请求，响应时间短的优先分配。Nginx本身是不支持fair的，如果需要使用这种调度算法，必须下载Nginx的upstream_fair模块。 url_hash（第三方）。按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，可以进一步提高后端缓存服务器的效率。Nginx本身是不支持url_hash的，如果需要使用这种调度算法，必须安装Nginx的hash软件包。 在HTTP Upstream模块中，可以通过server指令指定后端服务器的IP地址和端口，同时还可以设定每个后端服务器在负载均衡调度中的状态。常用的状态有： down，表示当前的server暂时不参与负载均衡。 backup，预留的备份机器。当其他所有的非backup机器出现故障或者忙的时候，才会请求backup机器，因此这台机器的压力最轻。 max_fails，允许请求失败的次数，默认为1。当超过最大次数时，返回proxy_next_upstream 模块定义的错误。 fail_timeout，在经历了max_fails次失败后，暂停服务的时间。max_fails可以和fail_timeout一起使用。 注意：当负载调度算法为ip_hash时，后端服务器在负载均衡调度中的状态不能是weight和backup。 基于域名的虚拟主机假设我们在本地开发有3个项目，分别在hosts里映射到本地的127.0.0.1上： 123127.0.0.1 www.iyangyi.com iyangyi.com127.0.0.1 api.iyangyi.com127.0.0.1 admin.iyangyi.com 有这样3个项目，分别对应于web根目录下的3个文件夹，我们用域名对应文件夹名字，这样子好记： 123/Users/yangyi/www/www.iyangyi.com//Users/yangyi/www/api.iyangyi.com//Users/yangyi/www/admin.iyangyi.com/ 每个目录下都有一个index.php文件，都是简单的输入自己的域名。 下面我们就来搭建这3个域名的虚拟主机，很显然，我们要新建3个server来完成。建议将对虚拟主机进行配置的内容写进另外一个文件，然后通过include指令包含进来，这样更便于维护和管理。不会使得这个nginx.conf内容太多： 123456789101112mainevents &#123; ....&#125;http &#123; .... include vhost/www.iyangyi.conf; include vhost/api.iyangyi.conf; include vhost/admin.iyangyi.conf; # 或者用 *.conf 包含 # include vhost/*.conf&#125; include：主模块指令，实现对配置文件所包含的文件的设定，可以减少主配置文件的复杂度。 既然每一个conf都是一个server，前面已经学习了一个完整的server写的了。下面就开始： 1234567891011121314151617# www.iyangyi.confserver &#123; listen 80; server_name www.iyangyi.com iyangyi.com; root /Users/yangyi/www/www.iyangyi.com/; index index.php index.html index.htm; access_log /usr/local/var/log/nginx/www.iyangyi.access.log main; error_log /usr/local/var/log/nginx/www.iyangyi.error.log error; location ~ \.php$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; &#125;&#125; 1234567891011121314151617# api.iyangyi.confserver &#123; listen 80; server_name api.iyangyi.com; root /Users/yangyi/www/api.iyangyi.com/; index index.php index.html index.htm; access_log /usr/local/var/log/nginx/api.iyangyi.access.log main; error_log /usr/local/var/log/nginx/api.iyangyi.error.log error; location ~ \.php$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; &#125;&#125; 1234567891011121314151617# admin.iyangyi.confserver &#123; listen 80; server_name admin.iyangyi.com; root /Users/yangyi/www/admin.iyangyi.com/; index index.php index.html index.htm; access_log /usr/local/var/log/nginx/admin.iyangyi.access.log main; error_log /usr/local/var/log/nginx/admin.iyangyi.error.log error; location ~ \.php$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; &#125;&#125; 这样3个很精简的虚拟域名就搭建好了。重启下nginx，然后打开浏览器访问一下这3个域名，就能看到对应的域名内容了。 反向代理Nginx 使用反向代理，主要是使用location模块下的proxy_pass选项。 来个最简单的。当我访问 mac 上的nginx 的 centos.iyangyi.com 的内容时候, 就反向代理到虚拟机centos上的 apache 192.168.33.10 的index.html页面。 192.168.33.10 中的html 是很简单的一句输出： 1centos apache2 index.html 在hosts里新加上这个域名： 12#vi /etc/hosts 127.0.0.1 centos.iyangyi.com 在vhost目录中新建一个conf server： 123456789101112#centos.iyangyi.confserver &#123; listen 80; server_name centos.iyangyi.com; access_log /usr/local/var/log/nginx/centos.iyangyi.access.log main; error_log /usr/local/var/log/nginx/centos.iyangyi.error.log error; location / &#123; proxy_pass http://192.168.33.10; &#125;&#125; 重启下nginx： 1sudo nginx -s reload 当然。proxy 还有其他的参数，比如：proxy_set_header 用来设置header头部信息参数转发等，等用了可以仔细看看。 负载均衡别被这个名字给吓住了，以为是什么很牛逼的东西的。其实不然。也很简单。 先简单说下负载均衡是干嘛的？举个例子：我们的小网站，刚开始就一台nginx服务器，后来，随着业务量增大，用户增多，一台服务器已经不够用了，我们就又多加了几台服务器。那么这几台服务器如何调度？如何均匀的提供访问？这就是负载均衡。 负载均衡的好处是可以集群多台机器一起工作，并且对外的IP和域名是一样的，外界看起来就好像一台机器一样。 基于 weight 权重的负载 先来一个最简单的，weight权重的： 123456789101112131415161718upstream webservers&#123; server 192.168.33.11 weight=10; server 192.168.33.12 weight=10; server 192.168.33.13 weight=10;&#125;server &#123; listen 80; server_name upstream.iyangyi.com; access_log /usr/local/var/log/nginx/upstream.iyangyi.access.log main; error_log /usr/local/var/log/nginx/upstream.iyangyi.error.log error; location / &#123; proxy_pass http://webservers; proxy_set_header X-Real-IP $remote_addr; &#125;&#125; 我们再来继续看几个参数 : max_fails和fail_timeout max_fails : 允许请求失败的次数，默认为1。当超过最大次数时，返回proxy_next_upstream 模块定义的错误。 fail_timeout : 在经历了max_fails次失败后，暂停服务的时间。max_fails可以和fail_timeout一起使用，进行健康状态检查。 12345upstream webservers&#123; server 192.168.33.11 weight=10 max_fails=2 fail_timeout=30s; server 192.168.33.12 weight=10 max_fails=2 fail_timeout=30s; server 192.168.33.13 weight=10 max_fails=2 fail_timeout=30s;&#125; down： 表示这台机器暂时不参与负载均衡。相当于注释掉了。 backup： 表示这台机器是备用机器，是其他的机器不能用的时候，这台机器才会被使用，俗称备胎 12345upstream webservers&#123; server 192.168.33.11 down; server 192.168.33.12 weight=10 max_fails=2 fail_timeout=30s; server 192.168.33.13 backup;&#125; 基于 ip_hash 的负载 这种分配方式，每个请求按访问IP的hash结果分配，这样来自同一个IP的访客固定访问一个后端服务器，有效解决了动态网页存在的session共享问题。 123456upstream webservers&#123; ip_hash; server 192.168.33.11 weight=1 max_fails=2 fail_timeout=30s; server 192.168.33.12 weight=1 max_fails=2 fail_timeout=30s; server 192.168.33.13 down;&#125; ip_hash 模式下，最好不要设置weight参数，因为你设置了，就相当于手动设置了，将会导致很多的流量分配不均匀。 ip_hash 模式下，backup参数不可用，加了会报错，为啥呢？因为，本身我们的访问就是固定的了，其实，备用已经不管什么作用了。 页面缓存页面缓存也是日常web 开发中很重要的一个环节，对于一些页面，我们可以将其静态化，保存起来，下次请求时候，直接走缓存，而不用去请求反相代理服务器甚至数据库服务了。从而减轻服务器压力。 nginx 也提供了简单而强大的下重定向，反向代理的缓存功能，只需要简单配置下，就能将指定的一个页面缓存起来。它的原理也很简单，就是匹配当前访问的url, hash加密后，去指定的缓存目录找，看有没有，有的话就说明匹配到缓存了。 我们先来看一下一个简单的页面缓存的配置： 12345678910111213141516http &#123; proxy_cache_path /data/nginx/cache levels=1:2 keys_zone=cache_zone:10m inactive=1d max_size=100m; upstream myproject &#123; ..... &#125; server &#123; .... location ~ *\.php$ &#123; proxy_cache cache_zone; #keys_zone的名字 proxy_cache_key $host$uri$is_args$args; #缓存规则 proxy_cache_valid any 1d; proxy_pass http://127.0.0.1:8080; &#125; &#125; ....&#125; 下面我们来一步一步说。用到的配置参数，主要是proxy_*前缀的很多配置。 首先需要在http中加入proxy_cache_path 它用来制定缓存的目录以及缓存目录深度制定等。它的格式如下： 1proxy_cache_path path [levels=number] keys_zone=zone_name:zone_size [inactive=time] [max_size=size]; path是用来指定 缓存在磁盘的路径地址。比如：/data/nginx/cache。那以后生存的缓存文件就会存在这个目录下。 levels用来指定缓存文件夹的级数，可以是：levels=1, levels=1:1, levels=1:2, levels=1:2:3 可以使用任意的1位或2位数字作为目录结构分割符，如 X, X:X,或 X:X:X 例如: 2, 2:2, 1:1:2，但是最多只能是三级目录。 那这个里面的数字是什么意思呢。表示取hash值的个数。比如： 现在根据请求地址localhost/index.php?a=4 用md5进行哈希，得到e0bd86606797639426a92306b1b98ad9 levels=1:2 表示建立2级目录，把hash最后1位(9)拿出建一个目录，然后再把9前面的2位(ad)拿来建一个目录, 那么缓存文件的路径就是/data/nginx/cache/9/ad/e0bd86606797639426a92306b1b98ad9 以此类推：levels=1:1:2表示建立3级目录，把hash最后1位(9)拿出建一个目录，然后再把9前面的1位(d)建一个目录, 最后把d前面的2位(8a)拿出来建一个目录 那么缓存文件的路径就是/data/nginx/cache/9/d/8a/e0bd86606797639426a92306b1b98ad9 keys_zone 所有活动的key和元数据存储在共享的内存池中，这个区域用keys_zone参数指定。zone_name指的是共享池的名称，zone_size指的是共享池的大小。注意每一个定义的内存池必须是不重复的路径，例如： 123proxy_cache_path /data/nginx/cache/one levels=1 keys_zone=one:10m;proxy_cache_path /data/nginx/cache/two levels=2:2 keys_zone=two:100m;proxy_cache_path /data/nginx/cache/three levels=1:1:2 keys_zone=three:1000m; inactive 表示指定的时间内缓存的数据没有被请求则被删除，默认inactive为10分钟。inactive=1d 1天。inactive=30m 30分钟。 max_size 表示单个文件最大不超过的大小。它被用来删除不活动的缓存和控制缓存大小，当目前缓存的值超出max_size指定的值之后，超过其大小后最少使用数据（LRU替换算法）将被删除。max_size=10g表示当缓存池超过10g就会清除不常用的缓存文件。 clean_time 表示每间隔自动清除的时间。clean_time=1m 1分钟清除一次缓存。 好。说完了这个很重要的参数。我们再来说在server模块里的几个配置参数： proxy_cache 用来指定用哪个keys_zone的名字，也就是用哪个目录下的缓存。上面我们指定了三个one, two,three 。比如，我现在想用one 这个缓存目录 : proxy_cache one proxy_cache_key 这个其实蛮重要的，它用来指定生成hash的url地址的格式。根据这个key映射成一个hash值，然后存入到本地文件。proxy_cache_key $host$uri表示无论后面跟的什么参数，都会访问一个文件，不会再生成新的文件。 而如果proxy_cache_key $is_args$args，那么传入的参数 localhost/index.php?a=4 与localhost/index.php?a=44 将映射成两个不同hash值的文件。 proxy_cache_key 默认是 “$scheme$host$request_uri”。但是一般我们会把它设置成：$host$uri$is_args$args 一个完整的url路径。 proxy_cache_valid 它是用来为不同的http响应状态码设置不同的缓存时间。 12proxy_cache_valid 200 302 10m;proxy_cache_valid 404 1m; 表示为http status code 为200和302的设置缓存时间为10分钟，404代码缓存1分钟。 如果只定义时间： 1proxy_cache_valid 5m; 那么只对代码为200, 301和302的code进行缓存。 同样可以使用any参数任何相响应： 123proxy_cache_valid 200 302 10m;proxy_cache_valid 301 1h;proxy_cache_valid any 1m; #所有的状态都缓存1小时 好。缓存的基本一些配置讲完了。也大致知道了怎么使用这些参数。现在开始实战！我们启动一台vagrant linux 机器 web1 (192.168.33.11) 用作远程代理机器，就不搞复杂的负载均衡了。 先在Mac本地加一个域名cache.iyangyi.com, 然后按照上面的配置在vhost 下新建一个proxy_cache.iyangyi.conf 文件: 12345678910111213141516171819proxy_cache_path /usr/local/var/cache levels=1:2 keys_zone=cache_zone:10m inactive=1d max_size=100m;server &#123; listen 80; server_name cache.iyangyi.com; access_log /usr/local/var/log/nginx/cache.iyangyi.access.log main; error_log /usr/local/var/log/nginx/cache.iyangyi.error.log error; add_header X-Via $server_addr; add_header X-Cache $upstream_cache_status; location / &#123; proxy_set_header X-Real-IP $remote_addr; proxy_cache cache_zone; proxy_cache_key $host$uri$is_args$args; proxy_cache_valid 200 304 1m; proxy_pass http://192.168.33.11; &#125;&#125; 打开审核元素或者firebug。看network网络请求选项，我们可以看到，Response Headers，在这里我们可以看到： 12X-Cache:MISSX-Via:127.0.0.1 X-cache 为 MISS 表示未命中，请求被传送到后端。因为是第一次访问，没有缓存，所以肯定是未命中。我们再刷新下，就发现其变成了HIT, 表示命中。它还有其他几种状态： MISS 未命中，请求被传送到后端 HIT 缓存命中 EXPIRED 缓存已经过期请求被传送到后端 UPDATING 正在更新缓存，将使用旧的应答 STALE 后端将得到过期的应答 BYPASS 缓存被绕过了 我们再去看看缓存文件夹 /usr/local/var/cache里面是否有了文件： 12345cache git:(master) cd a/13➜ 13 git:(master) ls5bd1af99bcb0db45c8bd601d9ee9e13a➜ 13 git:(master) pwd/usr/local/var/cache/a/13 已经生成了缓存文件。 我们在url 后面随便加一个什么参数，看会不会新生成一个缓存文件夹及文件：http://cache.iyangyi.com/?w=ww55 。因为我们使用的生成规则是全部url转换(proxy_cache_key $host$uri$is_args$args;) 查看 X-cache 为 MISS，再刷新 ，变成HIT。再去看一下缓存文件夹 /usr/local/var/cache。 12~cache git:(master) ls 4 a 果然又生成了一个4文件夹。 location 正则模块这一小节，主要来学习nginx中的URL重写怎么做。url重写模块，主要是在location模块面来实现，我们一点一点的看。 首先看下location 正则匹配的使用。还记得之前是如何用location来定位.php文件的吗? 12345location ~ \.php$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf;&#125; 我们用~来表示location开启正则匹配, 这样：location ~。还可以用这个来匹配静态资源，缓存它们，设置过期时间： 123456location ~ .*\.(gif|jpg|jpeg|bmp|png|ico|txt|mp3|mp4|swf)&#123; expires 15d;&#125;location ~ .*\.(css|js)&#123; expires 12h;&#125; expires 用来设置HTTP应答中的Expires和Cache-Control的头标时间，来告诉浏览器访问这个静态文件时，不用再去请求服务器，直接从本地缓存读取就可以了。 123语法： expires [time|epoch|max|off]默认值： expires off作用域： http, server, location 可以在time值中使用正数或负数。“Expires”头标的值将通过当前系统时间加上您设定的 time 值来获得。可以设置的参数如下： epoch 指定“Expires”的值为 1 January, 1970, 00:00:01 GMT。 max 指定“Expires”的值为 31 December 2037 23:59:59 GMT，“Cache-Control”的值为10年。 -1 指定“Expires”的值为 服务器当前时间 -1s,即永远过期。 负数：Cache-Control: no-cache。 正数或零：Cache-Control: max-age = #, # 会转换为指定时间的秒数。比如：1d、2h、3m。 off 表示不修改“Expires”和“Cache-Control”的值。 比如再看个例子: 控制图片等过期时间为30天 123location ~ \.(gif|jpg|jpeg|png|bmp|ico)$ &#123; expires 30d;&#125; 我们还可以控制哪一个文件目录的时间，比如控制匹配/resource/或者/mediatorModule/里所有的文件缓存设置到最长时间。 1234location ~ /(resource|mediatorModule)/ &#123; root /opt/demo; expires max;&#125; URL重写模块重写模块与很多模块一起使用。先看一下是怎么用的，看2个例子，然后我们再一点一点讲每个的使用方法： 12345678910location /download/ &#123; if ($forbidden) &#123; return 403; &#125; if ($slow) &#123; limit_rate 10k; &#125; rewrite ^/(download/.*)/media/(.*)\..*$ /$1/mp3/$2.mp3 break; ......&#125; 12345location / &#123; root html; index index.html index.htm; rewrite ^/bbs/(.*)$ http://192.168.18.201/forum/$1;&#125; 上面2个例子就是利用rewrite来完成URL重写的。我们慢慢来看它的用法。 break break和编程语言中的用法一样，就是跳出某个逻辑。 语法：break 默认值：none 使用字段：server, location, if 123if (!-f $request_filename) &#123; break;&#125; 上面这个例子就是在if里面使用break,意思是如果访问的文件名不存在，就跳出。后续会有更多的例子。 if if 判断一个条件，如果条件成立，则后面的大括号内的语句将执行，相关配置从上级继承。 语法：if (condition) { … } 默认值：none 使用字段：server, location 可以在判断语句中指定下列值： 一个变量的名称；不成立的值为：空字符传”“或者一些用“0”开始的字符串。 一个使用=或者!=运算符的比较语句。 使用符号*和模式匹配的正则表达式： ~为区分大小写的匹配。 ~*不区分大小写的匹配（firefox匹配FireFox）。 !和!*意为“不匹配的”。 使用-f和!-f检查一个文件是否存在。 使用-d和!-d检查一个目录是否存在。 使用-e和!-e检查一个文件，目录或者软链接是否存在。 使用-x和!-x检查一个文件是否为可执行文件。 $http_user_agent变量获取浏览器的agent，使用~ 来匹配大小写。用户如果使用的IE 浏览器，就执行if里面的操作。 123if ($http_user_agent ~ MSIE) &#123; rewrite ^(.*)$ /msie/$1 break;&#125; $request_method变量获取请求的方法，使用=来判断是否等于POST 。如果复合，就执行if 里面的操作。 123if ($request_method = POST ) &#123; return 405;&#125; $request_filename变量获取请求的文件名，使用!-f来匹配文件，如果不是一个文件名，就执行if 里面的逻辑。 1234if (!-f $request_filename) &#123; break; proxy_pass http://127.0.0.1;&#125; return 这个指令结束执行配置语句并为客户端返回状态代码，可以使用下列的值：204，400，402-406，408，410, 411, 413, 416与500-504。此外，非标准代码444将关闭连接并且不发送任何的头部。 语法：return code 默认值：none 使用字段：server, location, if rewrite 语法：rewrite regex replacement flag 默认值：none 使用字段：server, location, if rewrite用来重写url,有3个位置： regex 表示用来匹配的正则 replacement 表示用来替换的 flag 是尾部的标记 flag可以是以下的值： last - url重写后，马上发起一个新的请求，再次进入server块，重试location匹配，超过10次匹配不到报500错误，地址栏url不变 break - url重写后，直接使用当前资源，不再执行location里余下的语句，完成本次请求，地址栏url不变 redirect - 返回302临时重定向，url会跳转，爬虫不会更新url。 permanent - 返回301永久重定向。url会跳转。爬虫会更新url。 为空 - URL 不会变，但是内容已经变化，也是永久性的重定向。 上面的正则表达式的一部分可以用圆括号，方便之后按照顺序用$1-$9来引用。 我们来看几个例子： 需要将/photos/123456重写成/path/to/photos/12/1234/123456.png 可以这样： 1rewrite &quot;/photos/([0-9] &#123;2&#125;)([0-9] &#123;2&#125;)([0-9] &#123;2&#125;)&quot; /path/to/photos/$1/$1$2/$1$2$3.png; 下面是一些简单的常见的重写： 1234rewrite ^/js/base.core.v3.js /js/base.core.v3.dev.js redirect;rewrite ^/js/comment.frame.js /js/comment.frame.dev.js redirect;rewrite ^/live-static/(.*)$ http://live.bilibili.com/public/$1 last; 配置整理在此记录下Nginx服务器nginx.conf的配置文件说明, 部分注释收集与网络： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139# 运行用户user www-data; # 启动进程,通常设置成和cpu的数量相等worker_processes 1;# 全局错误日志及PID文件error_log /var/log/nginx/error.log;pid /var/run/nginx.pid;# 工作模式及连接数上限events &#123; use epoll; #epoll是多路复用IO(I/O Multiplexing)中的一种方式,但是仅用于linux2.6以上内核,可以大大提高nginx的性能 worker_connections 1024; #单个后台worker process进程的最大并发链接数 # multi_accept on; &#125;#设定http服务器，利用它的反向代理功能提供负载均衡支持http &#123; #设定mime类型,类型由mime.type文件定义 include /etc/nginx/mime.types; default_type application/octet-stream; #设定日志格式 access_log /var/log/nginx/access.log; #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，对于普通应用， #必须设为 on,如果用来进行下载等应用磁盘IO重负载应用，可设置为 off，以平衡磁盘与网络I/O处理速度，降低系统的uptime. sendfile on; #将tcp_nopush和tcp_nodelay两个指令设置为on用于防止网络阻塞 tcp_nopush on; tcp_nodelay on; #连接超时时间 keepalive_timeout 65; #开启gzip压缩 gzip on; gzip_disable &quot;MSIE [1-6]\.(?!.*SV1)&quot;; #设定请求缓冲 client_header_buffer_size 1k; large_client_header_buffers 4 4k; include /etc/nginx/conf.d/*.conf; include /etc/nginx/sites-enabled/*; #设定负载均衡的服务器列表 upstream mysvr &#123; #weigth参数表示权值，权值越高被分配到的几率越大 #本机上的Squid开启3128端口 server 192.168.8.1:3128 weight=5; server 192.168.8.2:80 weight=1; server 192.168.8.3:80 weight=6; &#125; server &#123; #侦听80端口 listen 80; #定义使用www.xx.com访问 server_name www.xx.com; #设定本虚拟主机的访问日志 access_log logs/www.xx.com.access.log main; #默认请求 location / &#123; root /root; #定义服务器的默认网站根目录位置 index index.php index.html index.htm; #定义首页索引文件的名称 fastcgi_pass www.xx.com; fastcgi_param SCRIPT_FILENAME $document_root/$fastcgi_script_name; include /etc/nginx/fastcgi_params; &#125; # 定义错误提示页面 error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root /root; &#125; #静态文件，nginx自己处理 location ~ ^/(images|javascript|js|css|flash|media|static)/ &#123; root /var/www/virtual/htdocs; #过期30天，静态文件不怎么更新，过期可以设大一点，如果频繁更新，则可以设置得小一点。 expires 30d; &#125; #PHP 脚本请求全部转发到 FastCGI处理. 使用FastCGI默认配置. location ~ \.php$ &#123; root /root; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /home/www/www$fastcgi_script_name; include fastcgi_params; &#125; #设定查看Nginx状态的地址 location /NginxStatus &#123; stub_status on; access_log on; auth_basic &quot;NginxStatus&quot;; auth_basic_user_file conf/htpasswd; &#125; #禁止访问 .htxxx 文件 location ~ /\.ht &#123; deny all; &#125; &#125; #第一个虚拟服务器 server &#123; #侦听192.168.8.x的80端口 listen 80; server_name 192.168.8.x; #对aspx后缀的进行负载均衡请求 location ~ .*\.aspx$ &#123; root /root;#定义服务器的默认网站根目录位置 index index.php index.html index.htm;#定义首页索引文件的名称 proxy_pass http://mysvr;#请求转向mysvr 定义的服务器列表 #以下是一些反向代理的配置可删除. proxy_redirect off; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; client_max_body_size 10m; #允许客户端请求的最大单文件字节数 client_body_buffer_size 128k; #缓冲区代理缓冲用户端请求的最大字节数， proxy_connect_timeout 90; #nginx跟后端服务器连接超时时间(代理连接超时) proxy_send_timeout 90; #后端服务器数据回传时间(代理发送超时) proxy_read_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时) proxy_buffer_size 4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 proxy_buffers 4 32k; #proxy_buffers缓冲区，网页平均在32k以下的话，这样设置 proxy_busy_buffers_size 64k; #高负荷下缓冲大小（proxy_buffers*2） proxy_temp_file_write_size 64k; #设定缓存文件夹大小，大于这个值，将从upstream服务器传 &#125; &#125;&#125; Nginx模块上面我们已经详细讲解了Nginx常用配置，从中我们已经体会到了，Nginx模块化配置的优点。其中，模块化设计类似于面向对象中的接口类，它增强了nginx源码的可读性、可扩充性和可维护性。 所以，Nginx有五大优点：模块化、事件驱动、异步、非阻塞、多进程单线程。由内核和模块组成的，其中内核完成的工作比较简单，仅仅通过查找配置文件将客户端请求映射到一个location block，然后又将这个location block中所配置的每个指令将会启动不同的模块去完成相应的工作。 模块划分Nginx的模块从结构上分为核心模块、基础模块和第三方模块： 核心模块：HTTP模块、EVENT模块和MAIL模块 基础模块：HTTP Access模块、HTTP FastCGI模块、HTTP Proxy模块和HTTP Rewrite模块， 第三方模块：HTTP Upstream Request Hash模块、Notice模块和HTTP Access Key模块。 Nginx的模块从功能上分为如下三类： Core(核心模块)：构建nginx基础服务、管理其他模块。 Handlers（处理器模块）：此类模块直接处理请求，并进行输出内容和修改headers信息等操作。Handlers处理器模块一般只能有一个。 Filters （过滤器模块）：此类模块主要对其他处理器模块输出的内容进行修改操作，最后由Nginx输出。 Proxies （代理类模块）：此类模块是Nginx的HTTP Upstream之类的模块，这些模块主要与后端一些服务比如FastCGI等进行交互，实现服务代理和负载均衡等功能。 Nginx的核心模块主要负责建立nginx服务模型、管理网络层和应用层协议、以及启动针对特定应用的一系列候选模块。其他模块负责分配给web服务器的实际工作： (1) 当Nginx发送文件或者转发请求到其他服务器，由Handlers(处理模块)或Proxies（代理类模块）提供服务； (2) 当需要Nginx把输出压缩或者在服务端加一些东西，由Filters(过滤模块)提供服务。 模块处理 当服务器启动，每个handlers(处理模块)都有机会映射到配置文件中定义的特定位置（location）；如果有多个handlers(处理模块)映射到特定位置时，只有一个会“赢”（说明配置文件有冲突项，应该避免发生）。处理模块以三种形式返回： OK ERROR 或者放弃处理这个请求而让默认处理模块来处理（主要是用来处理一些静态文件，事实上如果是位置正确而真实的静态文件，默认的处理模块会抢先处理）。 如果handlers(处理模块)把请求反向代理到后端的服务器，就变成另外一类的模块：load-balancers（负载均衡模块）。负载均衡模块的配置中有一组后端服务器，当一个HTTP请求过来时，它决定哪台服务器应当获得这个请求。 Nginx的负载均衡模块采用两种方法： 轮转法，它处理请求就像纸牌游戏一样从头到尾分发； IP哈希法，在众多请求的情况下，它确保来自同一个IP的请求会分发到相同的后端服务器。 如果handlers(处理模块)没有产生错误，filters（过滤模块）将被调用。多个filters（过滤模块）能映射到每个位置，所以（比如）每个请求都可以被压缩成块。它们的执行顺序在编译时决定。filters（过滤模块）是经典的“接力链表（CHAIN OF RESPONSIBILITY）”模型：一个filters（过滤模块）被调用，完成其工作，然后调用下一个filters（过滤模块），直到最后一个filters（过滤模块）。 过滤模块链的特别之处在于： 每个filters（过滤模块）不会等上一个filters（过滤模块）全部完成； 它能把前一个过滤模块的输出作为其处理内容；有点像Unix中的流水线； 过滤模块能以buffer（缓冲区）为单位进行操作，这些buffer一般都是一页（4K）大小，当然你也可以在nginx.conf文件中进行配置。这意味着，比如，模块可以压缩来自后端服务器的响应，然后像流一样的到达客户端，直到整个响应发送完成。 总之，过滤模块链以流水线的方式高效率地向客户端发送响应信息。 所以总结下上面的内容，一个典型的HTTP处理周期是这样的： 客户端发送HTTP请求 –&gt; Nginx基于配置文件中的位置选择一个合适的处理模块 -&gt; (如果有)负载均衡模块选择一台后端服务器 –&gt; 处理模块进行处理并把输出缓冲放到第一个过滤模块上 –&gt; 第一个过滤模块处理后输出给第二个过滤模块 –&gt; 然后第二个过滤模块又到第三个 –&gt; 依此类推 –&gt; 最后把响应发给客户端。 Nginx本身做的工作实际很少，当它接到一个HTTP请求时，它仅仅是通过查找配置文件将此次请求映射到一个location block，而此location中所配置的各个指令则会启动不同的模块去完成工作，因此模块可以看做Nginx真正的劳动工作者。通常一个location中的指令会涉及一个handler模块和多个filter模块（当然，多个location可以复用同一个模块）。handler模块负责处理请求，完成响应内容的生成，而filter模块对响应内容进行处理。 Nginx请求处理Nginx在启动时会以daemon形式在后台运行，采用多进程+异步非阻塞IO事件模型来处理各种连接请求。多进程模型包括一个master进程，多个worker进程，一般worker进程个数是根据服务器CPU核数来决定的。master进程负责管理Nginx本身和其他worker进程。 4个worker进程的父进程都是master进程，表明worker进程都是从父进程fork出来的，并且父进程的ppid为1，表示其为daemon进程。 需要说明的是，在nginx多进程中，每个worker都是平等的，因此每个进程处理外部请求的机会权重都是一致的。 Nginx的每一个Worker进程都管理着大量的线程，真正处理请求业务的是Worker之下的线程。worker进程中有一个ngx_worker_process_cycle()函数，执行无限循环，不断处理收到的来自客户端的请求，并进行处理，直到整个Nginx服务被停止。 worker 进程中，ngx_worker_process_cycle()函数就是这个无限循环的处理函数。在这个函数中，一个请求的简单处理流程如下： 操作系统提供的机制（例如 epoll, kqueue 等）产生相关的事件。 接收和处理这些事件，如是接收到数据，则产生更高层的 request 对象。 处理 request 的 header 和 body。 产生响应，并发送回客户端。 完成 request 的处理。 重新初始化定时器及其他事件。 多进程处理模型下面来介绍一个请求进来，多进程模型的处理方式： 首先，master进程一开始就会根据我们的配置，来建立需要listen的网络socket fd，然后fork出多个worker进程。 其次，根据进程的特性，新建立的worker进程，也会和master进程一样，具有相同的设置。因此，其也会去监听相同ip端口的套接字socket fd。 然后，这个时候有多个worker进程都在监听同样设置的socket fd，意味着当有一个请求进来的时候，所有的worker都会感知到。这样就会产生所谓的“惊群现象”。为了保证只会有一个进程成功注册到listenfd的读事件，nginx中实现了一个“accept_mutex”类似互斥锁，只有获取到这个锁的进程，才可以去注册读事件。其他进程全部accept 失败。 最后，监听成功的worker进程，读取请求，解析处理，响应数据返回给客户端，断开连接，结束。因此，一个request请求，只需要worker进程就可以完成。 进程模型的处理方式带来的一些好处就是：进程之间是独立的，也就是一个worker进程出现异常退出，其他worker进程是不会受到影响的；此外，独立进程也会避免一些不需要的锁操作，这样子会提高处理效率，并且开发调试也更容易。 如前文所述，多进程模型+异步非阻塞模型才是胜出的方案。单纯的多进程模型会导致连接并发数量的降低，而采用异步非阻塞IO模型很好的解决了这个问题；并且还因此避免的多线程的上下文切换导致的性能损失。 worker进程会竞争监听客户端的连接请求：这种方式可能会带来一个问题，就是可能所有的请求都被一个worker进程给竞争获取了，导致其他进程都比较空闲，而某一个进程会处于忙碌的状态，这种状态可能还会导致无法及时响应连接而丢弃discard掉本有能力处理的请求。这种不公平的现象，是需要避免的，尤其是在高可靠web服务器环境下。 针对这种现象，Nginx采用了一个是否打开accept_mutex选项的值，ngx_accept_disabled标识控制一个worker进程是否需要去竞争获取accept_mutex选项，进而获取accept事件。 ngx_accept_disabled值，nginx单进程的所有连接总数的八分之一，减去剩下的空闲连接数量，得到的这个ngx_accept_disabled。 当ngx_accept_disabled大于0时，不会去尝试获取accept_mutex锁，并且将ngx_accept_disabled减1，于是，每次执行到此处时，都会去减1，直到小于0。不去获取accept_mutex锁，就是等于让出获取连接的机会，很显然可以看出，当空闲连接越少时，ngx_accept_disable越大，于是让出的机会就越多，这样其它进程获取锁的机会也就越大。不去accept，自己的连接就控制下来了，其它进程的连接池就会得到利用，这样，nginx就控制了多进程间连接的平衡了。 一个简单的HTTP请求从 Nginx 的内部来看，一个 HTTP Request 的处理过程涉及到以下几个阶段： 初始化 HTTP Request（读取来自客户端的数据，生成 HTTP Request 对象，该对象含有该请求所有的信息）。 处理请求头。 处理请求体。 如果有的话，调用与此请求（URL 或者 Location）关联的 handler。 依次调用各 phase handler 进行处理。 在建立连接过程中，对于nginx监听到的每个客户端连接，都会将它的读事件的handler设置为ngx_http_init_request函数，这个函数就是请求处理的入口。在处理请求时，主要就是要解析http请求，比如：uri，请求行等，然后再根据请求生成响应。 在这里，我们需要了解一下 phase handler 这个概念。phase 字面的意思，就是阶段。所以 phase handlers 也就好理解了，就是包含若干个处理阶段的一些 handler。 在每一个阶段，包含有若干个 handler，再处理到某个阶段的时候，依次调用该阶段的 handler 对 HTTP Request 进行处理。 通常情况下，一个 phase handler 对这个 request 进行处理，并产生一些输出。通常 phase handler 是与定义在配置文件中的某个 location 相关联的。 一个 phase handler 通常执行以下几项任务： 获取 location 配置。 产生适当的响应。 发送 response header。 发送 response body。 当 Nginx 读取到一个 HTTP Request 的 header 的时候，Nginx 首先查找与这个请求关联的虚拟主机的配置。如果找到了这个虚拟主机的配置，那么通常情况下，这个 HTTP Request 将会经过以下几个阶段的处理（phase handlers）： NGX_HTTP_POST_READ_PHASE: 读取请求内容阶段 NGX_HTTP_SERVER_REWRITE_PHASE: Server 请求地址重写阶段 NGX_HTTP_FIND_CONFIG_PHASE: 配置查找阶段 NGX_HTTP_REWRITE_PHASE: Location请求地址重写阶段 NGX_HTTP_POST_REWRITE_PHASE: 请求地址重写提交阶段 NGX_HTTP_PREACCESS_PHASE: 访问权限检查准备阶段 NGX_HTTP_ACCESS_PHASE: 访问权限检查阶段 NGX_HTTP_POST_ACCESS_PHASE: 访问权限检查提交阶段 NGX_HTTP_TRY_FILES_PHASE: 配置项 try_files 处理阶段 NGX_HTTP_CONTENT_PHASE: 内容产生阶段 NGX_HTTP_LOG_PHASE: 日志模块处理阶段 在内容产生阶段，为了给一个 request 产生正确的响应，Nginx 必须把这个 request 交给一个合适的 content handler 去处理。如果这个 request 对应的 location 在配置文件中被明确指定了一个 content handler，那么Nginx 就可以通过对 location 的匹配，直接找到这个对应的 handler，并把这个 request 交给这个 content handler 去处理。这样的配置指令包括像，perl，flv，proxy_pass，mp4等。 如果一个 request 对应的 location 并没有直接有配置的 content handler，那么 Nginx 依次尝试： 如果一个 location 里面有配置 random_index on，那么随机选择一个文件，发送给客户端。 如果一个 location 里面有配置 index 指令，那么发送 index 指令指明的文件，给客户端。 如果一个 location 里面有配置 autoindex on，那么就发送请求地址对应的服务端路径下的文件列表给客户端。 如果这个 request 对应的 location 上有设置 gzip_static on，那么就查找是否有对应的.gz文件存在，有的话，就发送这个给客户端（客户端支持 gzip 的情况下）。 请求的 URI 如果对应一个静态文件，static module 就发送静态文件的内容到客户端。 内容产生阶段完成以后，生成的输出会被传递到 filter 模块去进行处理。filter 模块也是与 location 相关的。所有的 fiter 模块都被组织成一条链。输出会依次穿越所有的 filter，直到有一个 filter 模块的返回值表明已经处理完成。 这里列举几个常见的 filter 模块，例如： server-side includes。 XSLT filtering。 图像缩放之类的。 gzip 压缩。 在所有的 filter 中，有几个 filter 模块需要关注一下。按照调用的顺序依次说明如下： copy: 将一些需要复制的 buf(文件或者内存)重新复制一份然后交给剩余的 body filter 处理。 postpone: 这个 filter 是负责 subrequest 的，也就是子请求的。 write: 写输出到客户端，实际上是写到连接对应的 socket 上。 参考]]></content>
  </entry>
  <entry>
    <title><![CDATA[PHP实现十大经典排序]]></title>
    <url>%2F2018%2F09%2F09%2FPHP%E5%AE%9E%E7%8E%B0%E5%8D%81%E5%A4%A7%E7%BB%8F%E5%85%B8%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[概念时间频度 一个算法执行所耗费的时间，从理论上是不能算出来的，必须上机运行测试才能知道。但我们不可能也没有必要对每个算法都上机测试，只需知道哪个算法花费的时间多，哪个算法花费的时间少就可以了。并且每个算法花费的时间与算法中语句的执行次数成正比，哪个算法中语句执行次数多，它花费时间就多。一个算法中的语句执行次数称为语句频度或时间频度，记为T(n)。 时间复杂度 在时间频度中，n称为问题的规模，当n不断变化时，时间频度T(n)也会不断变化。但有时我们想知道它变化时呈现什么规律，为此，我们引入时间复杂度概念。一般情况下，算法中基本操作重复执行的次数是问题规模n的某个函数，用T(n)表示，若有某个辅助函数f(n)，使得当n趋近于无穷大时，T(n) / f(n) 的极限值为不等于零的常数，则称f(n)是T(n)的同数量级函数。记作T(n) = O( f(n) )，称O( f(n) )为算法的渐进时间复杂度，简称时间复杂度。 在计算时间复杂度的时候，先找出算法的基本操作，然后根据相应的各语句确定它的执行次数，再找出T(n)的同数量级（它的同数量级有以下：1，log2n, n, nlog2n, n2，n3，2n，n!），找出后，f(n) = 该数量级，若 T(n) / f(n)求极限可得到一常数c，则时间复杂度T(n) = O( f(n) )。 计算方法： [1] 如果算法的执行时间不随着问题规模n的增加而增长，即使算法中有上千条语句，其执行时间也不过是一个较大的常数。此类算法的时间复杂度是O(1)。 [2] 当有若干个循环语句时，算法的时间复杂度是由嵌套层数最多的循环语句中最内层频度f(n)决定的。 空间复杂度 一个程序的空间复杂度是指运行完一个程序所需内存的大小。利用程序的空间复杂度，可以对程序的运行所需要的内存多少有个预先估计。一个程序执行时除了需要存储空间和存储本身所使用的指令、常数、变量和输入数据外，还需要一些对数据进行操作的工作单元和存储一些为现实计算所需信息的辅助空间。 程序执行时所需存储空间包括以下两部分： [1] 固定部分。这部分空间的大小与输入/输出的数据的个数多少、数值无关。主要包括指令空间（即代码空间）、数据空间（常量、简单变量）等所占的空间。这部分属于静态空间。 [2] 可变空间。这部分空间主要包括动态分配的空间，以及递归栈所需的空间等。这部分的空间大小与算法有关。一个算法所需的存储空间用f(n)表示。S(n) = O( f(n) ) 其中n为问题的规模，S(n) 表示空间复杂度。 分类 排序算法可以分为内部排序和外部排序，内部排序是数据记录在内存中进行排序，而外部排序是指在排序期间全部对象太多，不能同时存放在内存中，必须根据排序过程的要求，不断在内，外存间移动的排序。常见的内部排序算法有：插入排序、希尔排序、选择排序、冒泡排序、归并排序、快速排序、堆排序、基数排序等。 用一张图概括： 参考 冒泡排序冒泡排序是一种简单直观的排序算法，它重复地走访过要排序的数列，一次比较两个元素，如果它们的顺序错误就把它们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端。 作为最简单的排序算法之一，冒泡排序给我的感觉就像 Abandon 在单词书里出现的感觉一样，每次都在第一页第一位，所以最熟悉。冒泡排序还有一种优化算法，就是立一个 flag，当在一趟序列遍历中元素没有发生交换，则证明该序列已经有序。但这种改进对于提升性能来说并没有什么太大作用。 算法步骤 比较相邻的元素。如果第一个比第二个大，就交换他们两个。 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。在这一点，最后的元素应该会是最大的数。 针对所有的元素重复以上的步骤，除了最后一个。 持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。 效率分析若文件的初始状态是正序的，一趟扫描即可完成排序。所需的关键字比较次数C和记录移动次数M均达到最小值：Cmin = n - 1, Mmin = 0，所以，冒泡排序最好的时间复杂度为O(n)。 若初始文件是反序的，需要进行n-1趟排序。每趟排序要进行 n-i 次关键字的比较(1 ≤ i ≤ n-1)，且每次比较都必须移动记录三次来达到交换记录位置。在这种情况下，比较和移动次数均达到最大值： Cmax = n(n-1)/2 = O(n²) Mmax = 3n(n-1)/2 = O(n²) 冒泡排序的最坏时间复杂度为O(n²)，综上，因此冒泡排序总的平均时间复杂度为O(n²)。 算法稳定性冒泡排序就是把小的元素往前调或者把大的元素往后调。比较是相邻的两个元素比较，交换也发生在这两个元素之间。所以，如果两个元素相等，我想你是不会再无聊地把他们交换一下的；如果两个相等的元素没有相邻，那么即使通过前面的两两交换把两个相邻起来，这时候也不会交换，所以相同元素的前后顺序并没有改变，所以冒泡排序是一种稳定排序算法。 代码实现1234567891011121314151617181920function bubbleSort(array $numbers = array())&#123; $count = count( $numbers ); if( $count &lt;= 1 ) return $numbers; for( $i = 0; $i &lt; $count-1; $i ++ ) &#123; for( $j = 0; $j &lt; $count-$i-1; $j ++ ) &#123; if( $numbers[$j] &gt; $numbers[$j + 1] ) &#123; $temp = $numbers[$j]; $numbers[$j] = $numbers[$j + 1]; $numbers[$j + 1] = $temp; &#125; &#125; &#125; return $numbers;&#125; 选择排序选择排序是一种简单直接的排序算法。它的工作原理如下，首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。 选择排序的主要优点与数据移动有关。如果某个元素位于正确的最终位置上，则它不会被移动。选择排序每次交换一对元素，它们当中至少有一个将被移动到其最终位置上，因此对n个元素进行排序总共进行至多n-1次交换。在所有的完全依靠交换去移动元素的排序方法中，选择排序属于好的一种。 算法步骤 首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置 再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。 重复第二步，直到所有元素均排序完毕。 效率分析在选择排序中，共需要进行n-1次选择和交换，每次选择需要进行 n-i 次比较(1 &lt;= i &lt;= n-1)，而每次交换最多需要3次移动，因此，总的比较次数 C = n (n - 1) / 2。 交换次数为O(n)，最好情况是，已经有序，交换0次；最坏情况是，逆序，交换n-1次。交换次数比冒泡排序较少，由于交换所需CPU时间比冒泡排序所需的CPU时间多，n值较小时，选择排序比冒泡排序快。 原地操作几乎是选择排序的唯一优点，当空间复杂度要求较高时，可以考虑选择排序；实际适用的场合非常罕见。 算法稳定性选择排序是给每个位置选择当前元素最小的，比如给第一个位置选择最小的，在剩余元素里面给第二个元素选择第二小的，依次类推，直到第n-1个元素，第n个 元素不用选择了，因为只剩下它一个最大的元素了。那么，在一趟选择，如果当前元素比一个元素小，而该小的元素又出现在一个和当前元素相等的元素后面，那么交换后稳定性就被破坏了。比较拗口，举个例子，序列5 8 5 2 9， 我们知道第一遍选择第1个元素5会和2交换，那么原序列中2个5的相对前后顺序就被破坏了，所以选择排序不是一个稳定的排序算法。 代码实现123456789101112131415161718192021222324252627function selectSort(array $numbers = array())&#123; $count = count( $numbers ); if( $count &lt;= 1 ) return $numbers; for($i = 0; $i &lt; $count-1; $i ++) &#123; $min = $i; for( $j = $i+1; $j &lt; $count; $j ++) &#123; if( $numbers[$min] &gt; $numbers[$j] ) &#123; $min = $j; &#125; &#125; if( $min != $i ) &#123; $temp = $numbers[$min]; $numbers[$min] = $numbers[$i]; $numbers[$i] = $temp; &#125; &#125; return $numbers;&#125; 插入排序插入排序是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置插入。插入排序在实现上，通常采用in-place排序（即只需要用到O(1)的额外空间的排序），因而在从后向前扫描过程中，需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。 算法步骤 从第一个元素开始，该元素可以认为已经被排序 取出下一个元素，在已经排序的元素序列中从后向前扫描 如果该元素（已排序大于新元素），将该元素移动到下一位置 重复步骤3，直到找到已排序的元素小于或者等于新元素的位置 将新元素插入到该位置后 重复步骤2~5 效率分析如果目标是把n个元素的序列升级排序，那么采用插入排序存在最好情况和最坏情况。最好情况就是，序列已经是升序排列了，在这种情况下，需要进行的比较操作需（n-1）次即可。最坏的情况就是，序列是降序排列，那么此时需要进行的比较共有1/2 * n(n-1)次。插入排序的赋值操作是比较操作的次数加上(n-1)次。平均来说插入排序算法复杂度为O(n2)。因而，插入排序不适合对于数据量比较大的排序应用。但是，如果需要排序的数据量很小，例如，量级小于千，那么插入排序还是一个不错的选择。插入排序在工业级库中也有着广泛的应用，在STL的sort算法和stdlib的qsort算法中，都将插入排序作为快速排序的补充，用于少量元素的排序。 算法稳定性插入排序是在一个已经有序的小序列的基础上，一次插入一个元素。当然，刚开始这个有序的小序列只有1个元素，就是第一个元素。比较是从有序序列的末尾开始，也就是想要插入的元素和已经有序的最大者开始比起，如果比它大则直接插入在其后面，否则一直往前找直到找到它该插入的位置。如果碰见一个和插入元素相等的，那么插入元素把想插入的元素放在相等元素的后面。所以，相等元素的前后顺序没有改变，从原无序序列出去的顺序就是排好序后的顺序，所以插入排序是稳定的。 代码实现1234567891011121314151617function insertionSort(array $numbers = array())&#123; $count = count( $numbers ); if( $count &lt;= 1 ) return $numbers; for($i = 1; $i &lt; $count; $i ++) &#123; $temp = $numbers[$i]; for($j = $i-1; $j &gt;= 0 &amp;&amp; $numbers[$j] &gt; $temp; $j --) &#123; $numbers[$j+1] = $numbers[$j]; &#125; $numbers[$j+1] = $temp; &#125; return $numbers;&#125; 希尔排序希尔排序是插入排序的一种，也称缩小增加排序，是直接插入排序算法的一种更高效的改进版本。希尔排序是非稳定排序算法。该方法因DL.Shell于1959年提出而得名。 该方法的基本思想是：先将整个待排元素序列分割成若干个子序列（由相隔某个“增量”的元素组成的）分别进行直接插入排序，然后依次缩减增量再进行排序，待整个序列中的元素基本有序（增量足够小）时，再对全体元素进行一次直接插入排序。因为直接插入排序在元素基本有序的情况下（接近最好情况），效率是很高的，因此希尔排序在时间效率上比前两种方法有较大提高。 算法步骤 取增量，一般取数组长度 / 2； 按增量取得一个子数列，对子数列按插入排序的方式处理； 将增量递减，重复1，2步骤； 直至增量均为0，数列已经排好序； 效率分析希尔排序是按照不同步长对元素进行插入排序，当刚开始元素很无序的时候，步长最大，所以插入排序的元素个数很少，速度很快；当元素基本有序了，步长很小，插入排序对于有序的序列效率很高。所以，希尔排序的时间复杂度会比O(n2)好一些。 算法稳定性希尔排序是按照不同步长对元素进行插入排序，当刚开始元素很无序的时候，步长最大，所以插入排序的元素个数很少，速度很快；当元素基本有序了，步长很小， 插入排序对于有序的序列效率很高。所以，希尔排序的时间复杂度会比O(n2)好一些。由于多次插入排序，我们知道一次插入排序是稳定的，不会改变相同元 素的相对顺序，但在不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，最后其稳定性就会被打乱，所以shell排序是不稳定的。 代码实现1234567891011121314151617181920function shellSort(array $numbers=array())&#123; $count = count( $numbers ); if( $count &lt;= 1 ) return $numbers; for($gap = floor($count/2); $gap &gt; 0; $gap = floor($gap/=2)) &#123; for($i=$gap; $i&lt;$count; ++$i) &#123; for($j = $i-$gap; $j &gt;= 0 &amp;&amp; $numbers[$j+$gap] &lt; $numbers[$j]; $j = $j - $gap) &#123; $temp = $numbers[$j]; $numbers[$j] = $numbers[$j+$gap]; $numbers[$j+$gap] = $temp; &#125; &#125; &#125; return $numbers;&#125; 归并排序归并排序是建立在归并操作上的一种有效的排序算法，该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序有，称为二路归并。 归并过程为：比较a[i]和a[j]的大小，若a[i]≤a[j]，则将第一个有序表中的元素a[i]复制到r[k]中，并令i和k分别加上1；否则将第二个有序表中的元素a[j]复制到r[k]中，并令j和k分别加上1，如此循环下去，直到其中一个有序表取完，然后再将另一个有序表中剩余的元素复制到r中从下标k到下标t的单元。归并排序的算法我们通常用递归实现，先把待排序区间[s,t]以中点二分，接着把左边子区间排序，再把右边子区间排序，最后把左区间和右区间用一次归并操作合并成有序的区间[s,t]。 算法步骤 申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列； 设定两个指针（即数组下标），最初位置分别为两个已经排序序列的起始位置； 比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到一下位置； 重复步骤3直到某一指针达到序列尾； 将另一序列剩下的所有元素直接复制到合并序列尾。 效率分析归并排序的效率是比较高的，设数列长为N，将数列分开成小数列一共要logN步，每步都是一个合并有序数列的过程，时间复杂度可以记为O(N)，故一共为O(n logn)。因为归并排序每次都是在相邻的数据中进行操作，所以归并排序在O(N logN)的几种排序方法（快速排序，归并排序，希尔排序，堆排序）也是效率比较高的。 算法稳定性归并排序是把序列递归地分成短序列，递归出口是短序列只有1个元素(认为直接有序)或者2个序列(1次比较和交换),然后把各个有序的段序列合并成一个有序的长序列，不断合并直到原序列全部排好序。可以发现，在1个或2个元素时，1个元素不会交换，2个元素如果大小相等也没有人故意交换，这不会破坏稳定 性。那么，在短的有序序列合并的过程中，稳定是是否受到破坏？没有，合并过程中我们可以保证如果两个当前元素相等时，我们把处在前面的序列的元素保存在结果序列的前面，这样就保证了稳定性。所以，归并排序也是稳定的排序算法。 代码实现123456789101112131415161718192021function mergeSort(array $numbers=array()) &#123; $count = count( $numbers ); if( $count &lt;= 1 ) return $numbers; // 将数组分成两份 $half = ceil( $count / 2 ); $half = ($count &gt;&gt; 1) + ($count &amp; 1); $arr2d = array_chunk($numbers, $half); $left = mergeSort($arr2d[0]); $right = mergeSort($arr2d[1]); while (count($left) &amp;&amp; count($right)) &#123; if ($left[0] &lt; $right[0]) $reg[] = array_shift($left); else $reg[] = array_shift($right); &#125; return array_merge($reg, $left, $right);&#125; 快速排序快速排序，又称划分交换排序，一种排序算法，最早由东尼·霍尔提出。在平均状况下，排序n个项目要O(n log n)次比较。在最坏状况下则需要O(n2)次比较，但这种状况并不常见。事实上，快速排序通常明显比其他O(n log n)算法更快，因为它的内部循环（inner loop）可以在大部分的架构上很有效率地被实现出来。 算法步骤快速排序使用分治法策略来把一个序列分为两个子序列，步骤： 从数列中挑出一个元素，称为”基准”。 重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区结束之后，该基准就处于数列的中间位置。这个称为分区操作。 递归地把小于基准值元素的子数列和大于基准值元素的子数列排序。 递归的最底部情形，是数列的大小是零或一，也就是永远都已经被排序好了。虽然一直递归下去，但是这个算法总会结束，因为在每次的迭代中，它至少会把一个元素摆到它最后的位置去。 效率分析从一开始快速排序平均需要花费O(n log n)时间的描述并不明显。但是不难观察到的是分区运算，数组的元素都会在每次循环中走访过一次，使用O(n)的时间。在使用结合的版本中，这项运算也是O(n)。 在最好的情况，每次我们运行一次分区，我们会把一个数列分为两个几近相等的片段。这个意思就是每次递归调用处理一半大小的数列。因此，在到达大小为一的数列前，我们只要作log n次嵌套的调用。这个意思就是调用树的深度是O(log n)。但是在同一层次结构的两个程序调用中，不会处理到原来数列的相同部分；因此，程序调用的每一层次结构总共全部仅需要O(n)的时间（每个调用有某些共同的额外耗费，但是因为在每一层次结构仅仅只有O(n)个调用，这些被归纳在O(n)系数中）。结果是这个算法仅需使用O(n log n)时间。 另外一个方法是为T(n)设立一个递归关系式，也就是需要排序大小为n的数列所需要的时间。在最好的情况下，因为一个单独的快速排序调用牵涉了O(n)的工作，加上对n/2大小之数列的两个递归调用，这个关系式可以是： T(n) = O(n) + 2T(n/2) 解决这种关系式类型的标准数学归纳法技巧告诉我们T(n) = O(n log n)。 事实上，并不需要把数列如此精确地分区；即使如果每个基准值将元素分开为99%在一边和1%在另一边，调用的深度仍然限制在100logn，所以全部运行时间依然是O(n log n)。 然而，在最坏的情况是，两子数列拥有大各为1和n-1，且调用树变成为一个n个嵌套调用的线性连串。第i次调用作了O(n-i)的工作量，且 ∑i = 0n(n - i) = O(n2)递归关系式为： T(n) = O(n) + T(1) + T(n - 1) = O(n) + T(n - 1) 这与插入排序和选择排序有相同的关系式，以及它被解为T(n) = O(n2)。 算法稳定性快速排序有两个方向，左边的i下标一直往右走，当a[i] &lt;= a[center_index]，其中center_index是中枢元素的数组下标，一般取为数组第0个元素。而右边的j下标一直往左走，当a[j] &gt; a[center_index]。如果i和j都走不动了，i &lt;= j, 交换a[i]和a[j],重复上面的过程，直到i&gt;j。交换a[j]和a[center_index]，完成一趟快速排序。在中枢元素和a[j]交换的时候，很有可能把前面的元素的稳定性打乱，比如序列为 5 3 3 4 3 8 9 10 11，现在中枢元素5和3(第5个元素，下标从1开始计)交换就会把元素3的稳定性打乱，所以快速排序是一个不稳定的排序算法，不稳定发生在中枢元素和a[j] 交换的时刻。 代码实现1234567891011121314151617function quickSort(array $numbers=array()) &#123; $count = count( $numbers ); if( $count &lt;= 1 ) return $numbers; $left = $right = array(); $mid_value = $numbers[0]; for ($i = 1; $i &lt; $count; $i++) &#123; if ($numbers[$i] &lt; $mid_value) $left[] = $numbers[$i]; else $right[] = $numbers[$i]; &#125; return array_merge(quickSort($left), (array)$mid_value, quickSort($right));&#125; 堆排序堆排序是指利用堆积树（堆）这种数据结构所设计的一种排序算法，它是选择排序的一种。可以利用数组的特点快速定位指定索引的元素。堆分为大根堆和小根堆，是完全二叉树。大根堆的要求是每个节点的值都不大于其父节点的值，即A[PARENT[i]] &gt;= A[i]。在数组的非降序排序中，需要使用的就是大根堆，因为根据大根堆的要求可知，最大的值一定在堆顶。 算法步骤 创建一个堆 H[0…n-1]； 把堆首（最大值）和堆尾互换； 把堆的尺寸缩小1，并调用 shift_down(0)，目的是把新的数组顶端数据调整到相应位置； 重复步骤 2，直到堆的尺寸为 1； 效率分析堆排序的时间，主要由建立初始堆和反复重建堆这两部分的时间开销构成，它们均是通过调用Heapify实现的。 平均性能 ：O(n * logn) 其他性能 ：由于建初始堆所需的比较次数较多，所以堆排序不适宜于记录数较少的文件。 算法稳定性我们知道堆的结构是节点i的孩子为2i和2i+1节点，大顶堆要求父节点大于等于其2个子节点，小顶堆要求父节点小于等于其2个子节点。在一个长为n 的序列，堆排序的过程是从第n/2开始和其子节点共3个值选择最大(大顶堆)或者最小(小顶堆),这3个元素之间的选择当然不会破坏稳定性。但当为n /2-1, n/2-2, …1这些个父节点选择元素时，就会破坏稳定性。有可能第n/2个父节点交换把后面一个元素交换过去了，而第n/2-1个父节点把后面一个相同的元素没 有交换，那么这2个相同的元素之间的稳定性就被破坏了。所以，堆排序不是稳定的排序算法。 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243function swap(&amp;$x, &amp;$y) &#123; $t = $x; $x = $y; $y = $t;&#125;function max_heapify(&amp;$arr, $start, $end)&#123; // 建立父节点指标和子节点指标 $dad = $start; $son = $dad * 2 + 1; if ($son &gt;= $end) //若子节点指标超过范围直接跳出函数 return; // 先比较两个子节点大小，选择最大的 if ($son + 1 &lt; $end &amp;&amp; $arr[$son] &lt; $arr[$son + 1]) $son++; // 如果父节点小于子节点时，交换父子内容再继续子节点和孙节点比较 if ($arr[$dad] &lt;= $arr[$son]) &#123; swap($arr[$dad], $arr[$son]); max_heapify($arr, $son, $end); &#125;&#125;function heap_sort($arr) &#123; $len = count($arr); //初始化，i从最后一个父节点开始调整 for ($i = $len / 2 - 1; $i &gt;= 0; $i--) max_heapify($arr, $i, $len); //先将第一个元素和已排好元素前一位做交换，再从新调整，直到排序完毕 for ($i = $len - 1; $i &gt; 0; $i--) &#123; swap($arr[0], $arr[$i]); max_heapify($arr, 0, $i); &#125; return $arr;&#125; 计数排序计数排序是一个非基于比较的排序算法，该算法于1954年由 Harold H. Seward 提出。它的优势在于对一定范围内的整数排序时，它的复杂度为O(n+k)（其中k是整数的范围），快于任何比较排序算法。当然这是一种牺牲空间换取时间的做法，而且当O(k)&gt;O(nlog(n))的时候其效率反而不如基于比较的排序（基于比较的排序的时间复杂度在理论上的下限是O(nlog(n))，如归并排序，堆排序） 算法步骤 找出待排序的数组中最大和最小的元素； 统计数组中每个值为i的元素出现的次数，存入数组 C 的第 i 项； 依次统计出C[i]表示数组中小于等于i的元素出现的个数； 从带排序列A的最后一个元素开始，将A[i]放到正确的位置（从后往前保证了排序的稳定性）。即前面又几个元素小于等于它，它就放在第几个位置。 效率分析由计数排序的代码实现可以看出，计数排序总的时间代价为O(k+n)。在实际工作中，当k=O(n)时，我们一般会采用计数排序，这时的运行时间为O(n)。 计数排序需要两个额外的数组用来对元素进行计数和保存排序的输出结果，所以空间复杂度为O(k+n)。 算法稳定性计数排序的一个重要性质是它是稳定的：具有相同值的元素在输出数组中的相对次序与它们在输入数组中的相对次序是相同的。也就是说，对两个相同的数来说，在输入数组中先出现的数，在输出数组中也位于前面。 计数排序的稳定性很重要的一个原因是：计数排序经常会被用于基数排序算法的一个子过程。我们将在下一篇文章中介绍，为了使基数排序能够正确运行，计数排序必须是稳定的。 代码实现12345678910111213141516171819202122232425262728293031function countingSort(array $numbers=array()) &#123; $count = count( $numbers ); if( $count &lt;= 1 ) return $numbers; // 找出待排序的数组中最大值和最小值 $min = min($numbers); $max = max($numbers); // 计算待排序的数组中每个元素的个数 $count_array = array(); for($i = $min; $i &lt;= $max; $i++) &#123; $count_array[$i] = 0; &#125; foreach($numbers as $v) &#123; $count_array[$v] = $count_array[$v] + 1; &#125; $ret = array(); foreach ($count_array as $k=&gt;$c) &#123; for($i = 0; $i &lt; $c; $i++) &#123; $ret[] = $k; &#125; &#125; return $ret;&#125; 桶排序桶排序或所谓的箱排序的原理是将数组分到有限数量的桶子里，然后对每个桶子再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序），最后将各个桶中的数据有序的合并起来。 假设有一组长度为N的待排序关键字序列K[1…n]。首先将这个序列划分成M个的子区间（桶）。然后基于某种映射函数，将待排序序列的关键字K映射到第i个桶中（即桶数组B的下标i），那么该关键字k就作用B[i]中的元素（每个桶B[i]都是一组大小为N/M的序列）。接着对每个桶B[i]中的所有元素进行比较排序（可以使用快速排序）。然后依次枚举输出B[0]…B[M]中的全部内容即是一个有序序列。 映射函数：bindex = f(k) 其中，bindex 为桶数组B的下标(即第bindex个桶)，k为待排序列的关键字。桶排序之所以能够高效，其关键在于这个映射函数，它必须做到：如果关键字k1 &lt; k2，那么f(k1) &lt;= f(k2)。也就是说B(i)中的最小数据都要大于B(i-1)中最大数据。很显然，映射函数的确定与数据本身的特点有很大的关系，我们下面举个例子： 假如待排序列K= {49、 38 、 35、 97 、 76、 73 、 27、 49 }。这些数据全部在1—100之间。因此我们定制10个桶，然后确定映射函数f(k)=k/10。则第一个关键字49将定位到第4个桶中(49/10=4)。依次将所有关键字全部堆入桶中，并在每个非空的桶中进行快速排序后得到如下图所示： 对上图只要顺序输出每个B[i]中的数据就可以得到有序序列了。 算法步骤 假设待排序的一组数统一的分布在一个范围中，并将这一范围划分成几个子范围，也就是桶。 将待排序的一组数，分档规入这些子桶，并将桶中的数据进行排序。 将各个桶中的数据有序的合并起来。 效率分析桶排序利用函数的映射关系，减少了几乎所有的比较工作。实际上，桶排序的f(k)值的计算，其作用就相当于快排中划分，已经把大量数据分割成了基本有序的数据块(桶)。然后只需要对桶中的少量数据做先进的比较排序即可。 对N个关键字进行桶排序的时间复杂度分为两个部分： a )、循环计算每个关键字的桶映射函数，这个时间复杂度是O(N)。 b )、利用先进的比较排序算法对每个桶内的所有数据进行排序，其时间复杂度为∑O(Ni * logNi) 。其中 Ni为第i个桶的数据量。 很显然，第b部分是桶排序性能好坏的决定因素。尽量减少桶内数据的数量是提高效率的唯一办法(因为基于比较排序的最好平均时间复杂度只能达到O(N*logN)了)。因此，我们需要尽量做到下面两点： a )、映射函数f(k)能够将N个数据平均的分配到M个桶中，这样每个桶就有[N/M]个数据量。 b )、尽量的增大桶的数量。极限情况下每个桶只能得到一个数据，这样就完全避开了桶内数据的“比较”排序操作。 当然，做到这一点很不容易，数据量巨大的情况下，f(k)函数会使得桶集合的数量巨大，空间浪费严重。这就是一个时间代价和空间代价的权衡问题了。 对于N个待排数据，M个桶，平均每个桶[N/M]个数据的桶排序平均时间复杂度为：O(N)+O(M(N/M)log(N/M))=O(N+N(logN-logM)) = O(N+NlogN-N*logM) 当N=M时，即极限情况下每个桶只有一个数据时。桶排序的最好效率能够达到O(N)。 总结： 桶排序的平均时间复杂度为线性的O(N+C)，其中C=N*(logN-logM)。如果相对于同样的N，桶数量M越大，其效率越高，最好的时间复杂度达到O(N)。当然桶排序的空间复杂度 为O(N+M)，如果输入数据非常庞大，而桶的数量也非常多，则空间代价无疑是昂贵的。 算法稳定性桶排序中，假如升序排列，a已经在桶中，b插进来是永远都会a右边的(因为一般是从右到左，如果不小于当前元素，则插入改元素的右侧)，所以桶排序是稳定的。 代码实现12345678910111213141516171819202122function bucketSort($max, $array)&#123; //填充木桶 $arr = array_fill(0, $max+1, 0); //开始标示木桶 for($i = 0; $i &lt;= count($array)-1 ; $i++) &#123; $arr[$array[$i]] ++; &#125; $mutomg = array(); //开始从木桶中拿出数据 for($i = 0; $i &lt;= $max; $i ++) &#123; for($j = 1; $j &lt;= $arr[$i]; $j ++) &#123; //这一行主要用来控制输出多个数字 $mutong[] = $i; &#125; &#125; return $mutong;&#125; 基数排序基数排序是一种非比较型整数排序算法，其原理是将整数按位数切割成不同的数字，然后按每个位数分别比较。基数排序的发明可以追溯到 1887 年赫尔曼·何乐礼在打孔卡片制表机 (Tabulation Machine)上的贡献。 排序过程：将所有待比较数值（正整数）统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后，数列就变成一个有序序列。 基数排序法会使用到桶，顾名思义，通过将要比较的位（个位、十位、百位…），将要排序的元素分配到0~9个桶中，借以达到排序的作用，在某些时候，基数排序法的效率高于其它的比较性排序法。 算法步骤基数排序的方式可以采用 LSD (Least sgnificant digital) 或 MSD (Most sgnificant digital)，LSD 的排序方式由键值的最右边开始，而 MSD 则相反，由键值的最左边开始。 以 LSD 为例，假设原来有一串数值如下所示： 36 9 0 25 1 49 64 16 81 4 首先根据个位数的数值，按照个位值等于桶编号的方式，将它们分配至编号0至9的桶子中： 编号 0 1 2 3 4 5 6 7 8 9 0 1 64 25 36 9 81 4 16 49 然后，将这些数字按照桶以及桶内部的排序连接起来： 0 1 81 64 4 25 36 16 9 49 接着按照十位的数值，分别对号入座： |编号|0|1|2|3|4|5|6|7|8|9|| |0|16|25|36|49||64||81||| |1||||||||||| |4||||||||||| |9|||||||||| 最后按照次序重现连接，完成排序： 0 1 4 9 16 25 36 49 64 81 效率分析基数排序的时间复杂度是O(k n)，其中n是排序元素个数，k是数字位数。注意这不是说这个时间复杂度一定优于O(n log(n) )，k的大小取决于数字位的选择（比如比特位数），和待排序数据所属数据类型的全集大小；k决定了进行多少轮处理，而n是每轮处理的操作数目。 以排序n个不同整数来举例，假定这些整数以B为底，这样每位数都有B个不同的数字，k = logBN，N是待排序数据类型全集的势。虽然有B个不同的数字，需要B个不同的桶，但在每一轮处理中，判断每个待排序数据项只需要一次计算确定对应数位的值，因此在每一轮处理的时候都需要平均n次操作来把整数放到合适的桶中去，所以就有：k ≈ logBN ，所以，基数排序的平均时间$T$就是：T ≈ LogB(N) * n其中前一项是一个与输入数据无关的常数，当然该项不一定小于log n。 如果考虑和比较排序进行对照，基数排序的形式复杂度虽然不一定更小，但由于不进行比较，因此其基本操作的代价较小，而且在适当选择的$B$之下，k一般不大于log n，所以基数排序一般要快过基于比较的排序，比如快速排序。 算法稳定性基数排序是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优 先级排序，最后的次序就是高优先级高的在前，高优先级相同的低优先级高的在前。基数排序基于分别排序，分别收集，所以其是稳定的排序算法。 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041function GetNumInPos($number, $pos)&#123; $number = strrev( $number ); return $number[ -- $pos ];&#125;function LsdRadixSort(array $numbers = array(), $tpos=1) &#123; $count = count( $numbers ); if( $count &lt;= 1 ) return $numbers; $bucket = array(); for($i = 0; $i &lt; 10; $i ++) &#123; $bucket[$i] = array(0); &#125; // 由低 $p=1 至高位 $p&lt;=$d 循环排序 for($p = 1; $p &lt;= $tpos; $p ++) &#123; // 将对应数据按当前位的数值放入桶里 for($i = 0; $i &lt; $count; $i ++) &#123; $n = GetNumInPos($numbers[$i], $p); $index = ++ $bucket[$n][0]; $bucket[$n][$index] = $numbers[$i]; &#125; // 收集桶里的数据 for($i = 0, $j = 0; $i &lt; 10; $i ++) &#123; for($num = 1; $num &lt;= $bucket[$i][0]; $num ++) &#123; $numbers[$j++] = $bucket[$i][$num]; &#125; $bucket[$i][0] = 0; &#125; &#125; return $numbers;&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[MySQL数据库主从同步安装与配置]]></title>
    <url>%2F2018%2F09%2F07%2FMySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[MySQL的主从同步是一个很成熟的架构，优点为：① 在从服务器可以执行查询工作(即我们常说的读功能)，降低主服务器压力；② 在从主服务器进行备份，避免备份期间影响主服务器服务；③ 当主服务器出现问题时，可以切换到从服务器。所以我在项目部署和实施中经常会采用这种方案。 数据库目录及其它 my.cnf配置文件 /etc/my.cnf mysql数据库位置 datadir=/var/lib/mysql 主数据库：192.168.2.119 从数据库：192.168.2.220 操作系统：RHEL5.x 32位 服务器类型: 虚拟机 mysql5.0.77 安装:① 配置好linux的yum服务后，直接yum -y install mysql即可 附：安装php\mysql一条命令安装： 1yum -y install httpd php mysql mysql-server php-mysql ② 启动MySQL 1service mysqld start(restart|stop) 一、设置主库 1、修改主库my.cnf,主要是设置个不一样的id和logbin（#这部可依具体环境而定，压力大的化可采用huge.cnf） 1vi /etc/my.cnf 记住这部分一定要配置在[mysqld]后面，否则无法找到从节点，各个配置项的含义可自己查阅文档 1234[mysqld]server-id=1log-bin=mysql-bin # 启用二进制日志binlog-ignore-db=information_schema,cluster,mysql #忽略写入binlog的库 2、启动主库生效 1service mysqld restart 3、登陆主库 1mysql -u root -p 4、赋予从库权限帐号，允许用户在主库上读取日志 1grant all privileges on *.* to &apos;用户名&apos;@&apos;%&apos; identified by &apos;密码&apos;; 5、检查创建是否成功 1select user,host from mysql.user; 6、锁主库表（防止数据库状态值变化，锁定后，这时候只能读，不能写，写请求会在解锁后执行） 1flush tables with read lock; 7、显示主库信息 记录File和Position，从库设置将会用到 1show master status; 说明，如果执行这个步骤始终为Empty set(0.00 sec)，那说明前面的my.cnf没配置对。 8、另开一个终端登陆220，打包主库迁移数据（如果你使用的yum安装，有默认数据库并未做任何改动，则不需要进行拷贝） 目的是为了保证两台服务器的mysql数据库一致，这里可以自行tar打包或者使用mysqldump命令备份恢复的方式进行。 二、设置从库 1、传输拿到主库包、解包 登陆从库 从上一步中备份的数据库恢复到220服务器节点上。 2、在119节点上解锁主库表（对应第一点设置主库中第6步锁主库表的操作） 1unlock tables; 3、在220节点上修改从库my.cnf（位置一样） 记住这部分一定要配置在[mysqld]后面，否则无法找到从节点，各个配置项的含义可自己查阅文档 123456789101112[mysqld]log-bin=mysql-binserver-id=2binlog-ignore-db=information_schema,cluster,mysqlreplicate-do-db=testreplicate-ignore-db=mysqllog-slave-updatesslave-skip-errors=allslave-net-timeout=60master-host=192.168.2.119master-user=rootmaster-password=pfingo 4、在220节点上验证连接主库 1mysql -h 192.168.2.119 -u 用户名 -p 5、在220节点从库上设置同步 设置连接MASTER MASTER_LOG_FILE为主库的File，MASTER_LOG_POS为主库的Position 注意下面第二条命令语句中的master_log_file=’mysql-bin.000001’, master_log_pos=98;对应为前面在主库中执行的show master status;结果 123mysql&gt; slave stop;mysql&gt; change master to master_host=&apos;192.168.2.119&apos;,master_user=&apos;root&apos;,master_password=&apos;pfingo&apos;,master_log_file=&apos;mysql-bin.000001&apos;, master_log_pos=98;mysql&gt; slave start; 6、启动从库服务 1mysql&gt; slave start; 7、进行测试 在主库上的test库上建立名为myTest的表 123456789mysql&gt; CREATE TABLE `myTest` (`id` INT( 5 ) UNSIGNED NOT NULL AUTO_INCREMENT ,`username` VARCHAR( 20 ) NOT NULL ,`password` CHAR( 32 ) NOT NULL ,`last_update` DATETIME NOT NULL ,`number` FLOAT( 10 ) NOT NULL ,`content` TEXT NOT NULL ,PRIMARY KEY ( `id` )) ENGINE = MYISAM ; 在从表中马上看到了效果，主从同步成功了； 为了更进一步验证在从库上输入show slave status\G; 1mysql&gt; show slave status\G; Slave_IO_Running: Yes(网络正常)； Slave_SQL_Running: Yes(表结构正常) 进一步验证了以上过程的正确性。 参考1]]></content>
  </entry>
  <entry>
    <title><![CDATA[数据库与死锁]]></title>
    <url>%2F2018%2F09%2F07%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E6%AD%BB%E9%94%81%2F</url>
    <content type="text"><![CDATA[死锁定义 所谓死锁： 是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。 此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。 由于资源占用是互斥的，当某个进程提出申请资源后，使得有关进程在无外力协助下，永远分配不到必需的资源而无法继续运行，这就产生了一种特殊现象死锁。 产生死锁的必要条件 互斥条件：指进程对所分配到的资源进行排它性使用，即在一段时间内某资源只由一个进程占用。如果此时还有其它进程请求资源，则请求者只能等待，直至占有资源的进程用毕释放。 请求和保持条件：指进程已经保持至少一个资源，但又提出了新的资源请求，而该资源已被其它进程占有，此时请求进程阻塞，但又对自己获得的其它资源保持不放。 不剥夺条件：指进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放。 环路等待条件：指在发生死锁时，必然存在一个进程——资源的环形链，即进程集合{P0，P1，P2，···，Pn}中的P0正在等待一个P1占用的资源；P1正在等待P2占用的资源，……，Pn正在等待已被P0占用的资源。 处理死锁的基本方式 预防死锁。这是一种较简单和直观的事先预防的方法。方法是通过设置某些限制条件，去破坏产生死锁的四个必要条件中的一个或者几个，来预防发生死锁。 预防死锁是一种较易实现的方法，已被广泛使用。但是由于所施加的限制条件往往太严格，可能会导致系统资源利用率和系统吞吐量降低。 避免死锁。该方法同样是属于事先预防的策略，但它并不须事先采取各种限制措施去破坏产生死锁的的四个必要条件，而是在资源的动态分配过程中，用某种方法去防止系统进入不安全状态，从而避免发生死锁。 检测死锁。这种方法并不须事先采取任何限制性措施，也不必检查系统是否已经进入不安全区，此方法允许系统在运行过程中发生死锁。 但可通过系统所设置的检测机构，及时地检测出死锁的发生，并精确地确定与死锁有关的进程和资源，然后采取适当措施，从系统中将已发生的死锁清除掉。 解除死锁。这是与检测死锁相配套的一种措施。当检测到系统中已发生死锁时，须将进程从死锁状态中解脱出来。 常用的实施方法是撤销或挂起一些进程，以便回收一些资源，再将这些资源分配给已处于阻塞状态的进程，使之转为就绪状态，以继续运行。 死锁的检测和解除措施，有可能使系统获得较好的资源利用率和吞吐量，但在实现上难度也最大。 如何处理MySQL数据库的死锁问题 登录MySQL 1mysql -h xxxx.xxx.xxx -P 3306 -u username -p 查看MySQL数据库的死锁信息 1show engine innodb status \G; 找到“LATEST DETECTED DEADLOCK”一节内容。 查看当前的事务 1SELECT * FROM information_schema.innodb_trx \G; 查看当前锁定的事务 1SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS; 查看当前等锁的事务 1SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS; 查在抢资源进程 1SELECT * FROM INFORMATION_SCHEMA.INNODB_TRX; 杀掉它们 1Kill trx_mysql_thread_id; 参考1参考2]]></content>
  </entry>
  <entry>
    <title><![CDATA[接口和抽象类区别]]></title>
    <url>%2F2018%2F09%2F07%2F%E6%8E%A5%E5%8F%A3%E5%92%8C%E6%8A%BD%E8%B1%A1%E7%B1%BB%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[抽象类 abstract class 抽象类是指在 class 前加了 abstract 关键字且存在抽象方法（在类方法 function 关键字前加了 abstract 关键字）的类。 抽象类不能被直接实例化。抽象类中只定义（或部分实现）子类需要的方法。子类可以通过继承抽象类并通过实现抽象类中的所有抽象方法，使抽象类具体化。 如果子类需要实例化，前提是它实现了抽象类中的所有抽象方法。如果子类没有全部实现抽象类中的所有抽象方法，那么该子类也是一个抽象类，必须在 class 前面加上 abstract 关键字，并且不能被实例化。 如果 B 实现了 A 的抽象方法 abstract_func() ，那么 B 中 abstract_func() 方法的访问控制不能比 A 中 abstract_func() 的访问控制更严格。 接口 interface 抽象类提供了具体实现的标准，而接口则是纯粹的模版。接口只定义功能，而不包含实现的内容。接口用关键字 interface 来声明。 interface 是完全抽象的，只能声明方法，而且只能声明 public 的方法，不能声明 private 及 protected 的方法，不能定义方法体，也不能声明实例变量 。 然而， interface 却可以声明常量变量 。但将常量变量放在 interface 中违背了其作为接口的作用而存在的宗旨，也混淆了 interface 与类的不同价值。 如果的确需要，可以将其放在相应的 abstract class 或 Class 中。 任何实现接口的类都要实现接口中所定义的所有方法，否则该类必须声明为 abstract 。 一个类可以在声明中使用 implements 关键字来实现某个接口。这么做之后，实现接口的具体过程和继承一个仅包含抽象方法的抽象类是一样的。 一个类可以同时继承一个父类和实现任意多个接口。 extends 子句应该在 implements 子句之前。 PHP 只支持继承自一个父类，因此 extends 关键字后只能跟一个类名。 接口不可以实现另一个接口，但可以继承多个。 抽象类和接口的异同 相同点： (1) 两者都是抽象类，都不能实例化。 (2) interface 实现类及 abstract class 的子类都必须要实现已经声明的抽象方法。 不同点： (1) interface 需要实现，要用 implements ，而 abstract class 需要继承，要用 extends 。 (2) 一个类可以实现多个 interface ，但一个类只能继承一个 abstract class 。 (3) interface 强调特定功能的实现，而 abstract class 强调所属关系。 (4) 尽管 interface 实现类及 abstract class 的子类都必须要实现相应的抽象方法，但实现的形式不同。 interface 中的每一个方法都是抽象方法，都只是声明的 (declaration, 没有方法体 ) ，实现类必须要实现。而 abstract class 的子类可以有选择地实现。这个选择有两点含义： a) abstract class 中并非所有的方法都是抽象的，只有那些冠有 abstract 的方法才是抽象的，子类必须实现。那些没有 abstract 的方法，在 abstract class 中必须定义方法体； b) abstract class 的子类在继承它时，对非抽象方法既可以直接继承，也可以覆盖；而对抽象方法，可以选择实现，也可以留给其子类来实现，但此类必须也声明为抽象类。既是抽象类，当然也不能实例化。 (5) abstract class 是 interface 与 class 的中介。 abstract class 在 interface 及 class 中起到了承上启下的作用。一方面， abstract class 是抽象的，可以声明抽象方法，以规范子类必须实现的功能；另一方面，它又可以定义缺省的方法体，供子类直接使用或覆盖。另外，它还可以定义自己的实例变量，以供子类通过继承来使用。 (6) 接口中的抽象方法前不用也不能加 abstract 关键字，默认隐式就是抽象方法，也不能加 final 关键字来防止抽象方法的继承。而抽象类中抽象方法前则必须加上 abstract 表示显示声明为抽象方法。 (7) 接口中的抽象方法默认是 public 的，也只能是 public 的，不能用 private ， protected 修饰符修饰。而抽象类中的抽象方法则可以用 public ， protected 来修饰，但不能用 private 。 (8) 抽象类的继承是is a的关系。定义该体系的基本共性内容。接口的实现是like a的关系。定义体系的额外功能。 interface 的应用场合 (1) 类与类之间需要特定的接口进行协调，而不在乎其如何实现。 (2) 作为能够实现特定功能的标识存在，也可以是什么接口方法都没有的纯粹标识。 (3) 需要将一组类视为单一的类，而调用者只通过接口来与这组类发生联系。 (4) 需要实现特定的多项功能，而这些功能之间可能完全没有任何联系。 abstract class 的应用场合 一句话，在既需要统一的接口，又需要实例变量或缺省的方法的情况下，就可以使用它。最常见的有： (1) 定义了一组接口，但又不想强迫每个实现类都必须实现所有的接口。可以用 abstract class 定义一组方法体，甚至可以是空方法体，然后由子类选择自己所感兴趣的方法来覆盖。 (2) 某些场合下，只靠纯粹的接口不能满足类与类之间的协调，还必需类中表示状态的变量来区别不同的关系。 abstract 的中介作用可以很好地满足这一点。 (3) 规范了一组相互协调的方法，其中一些方法是共同的，与状态无关的，可以共享的，无需子类分别实现；而另一些方法却需要各个子类根据自己特定的状态来实现特 定的功能 。 参考1]]></content>
  </entry>
  <entry>
    <title><![CDATA[手机号归属地查询接口]]></title>
    <url>%2F2018%2F09%2F04%2F%E6%89%8B%E6%9C%BA%E5%8F%B7%E5%BD%92%E5%B1%9E%E5%9C%B0%E6%9F%A5%E8%AF%A2%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[淘宝网 1234API地址： http:``//tcc.taobao.com/cc/json/mobile_tel_segment.htm?tel=15850781443参数：tel：手机号码返回：JSON 拍拍 123456API地址： http:``//virtual.paipai.com/extinfo/GetMobileProductInfo?mobile=15850781443&amp;amount=10000&amp;callname=getPhoneNumInfoExtCallback参数：mobile：手机号码callname：回调函数amount：未知（必须）返回：JSON 财付通 1234API地址： http:``//life.tenpay.com/cgi-bin/mobile/MobileQueryAttribution.cgi?chgmobile=15850781443参数：chgmobile：手机号码返回：xml 百付宝 123456API地址： https:``//www.baifubao.com/callback?cmd=1059&amp;callback=phone&amp;phone=15850781443参数：phone：手机号码callback：回调函数cmd：未知（必须）返回：JSON 有道api接口 12345678910111213141516接口地址：http:``//www.youdao.com/smartresult-xml/search.s?type=mobile&amp;q=13892101112参数说明：type ： 参数手机归属地固定为mobileq ： 手机号码返回XML格式：&lt;?xml version=``&quot;1.0&quot;``encoding=``&quot;gbk&quot;``?&gt;&lt;smartresult&gt;&lt;product type=``&quot;mobile&quot;``&gt;&lt;phonenum&gt;13892101112&lt;/phonenum&gt;&lt;location&gt;陕西 延安&lt;/location&gt;&lt;/product&gt;&lt;/smartresult&gt;或者http:``//www.youdao.com/smartresult-xml/search.s?jsFlag=true&amp;type=mobile&amp;q=手机号码返回JSON格式：fYodaoCallBack(1, &#123;‘product’:``&apos;mobile’,&apos;``phonenum’:’13892101112′,’location’:&apos;陕西 延安’&#125; , ”); 096.me api接口 12http:``//www.096.me/api.php?phone=手机号&amp;mode=&#123;txt,xml&#125;举例：http:``//www.096.me/api.php?phone=13892101111&amp;mode=txt]]></content>
  </entry>
  <entry>
    <title><![CDATA[移位运算]]></title>
    <url>%2F2018%2F08%2F29%2F%E7%A7%BB%E4%BD%8D%E8%BF%90%E7%AE%97%2F</url>
    <content type="text"><![CDATA[逻辑左移时，最高位丢失，最低位补0； 逻辑右移时，最高位补0，最低位丢失； 算术左移时，依次左移一位，尾部补0，最高的符号位保持不变。 算术右移时，依次右移一位，尾部丢失，符号位右移后，原位置上复制一个符号位； 循环左移时，将最高位重新放置最低位 循环右移时，将最低位重新放置最高位 例如： 1010100010101 逻辑左移一位结果为 0101000101010 逻辑右移一位结果为 0101010001010 算术左移一位结果为 1101000101010 算术右移一位结果为 1101010001010 循环左移一位结果为 0101000101011 循环右移一位结果为 1101010001010]]></content>
  </entry>
  <entry>
    <title><![CDATA[macOS环境部署Hexo]]></title>
    <url>%2F2018%2F08%2F29%2FmacOS%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2Hexo%2F</url>
    <content type="text"><![CDATA[安装XcodeMac App Store下载安装 安装Node.js1234$ brew install nvm$ mkdir ~/.nvm$ export NVM_DIR=~/.nvm$ . $(brew --prefix nvm)/nvm.sh 安装Hexo123456npm install -g hexo-clicd ~/Desktop/hexo-bloghexo initnpm installhexo generatehexo server 打开 http://localhost:4000/ ，会看到效果。 部署Github仓库 cd到你的博客文件夹 vim _config.yml 加上如下 1234deploy: type: git repository: https://github.com/KevinCoderX/KevinCoderX.github.io.git branch: master 执行命令 123npm install hexo-deployer-git --savehexo generatehexo deploy 装饰你的博客1git clone https://github.com/theme-next/hexo-theme-next themes/next _config.yml里theme的名称修改为next 123hexo clean //清除缓存文件 (db.json) 和已生成的静态文件 (public)hexo g //生成缓存和静态文件hexo d //重新部署到服务器 写下你的博客1hexo new post &quot;我的第一篇博客&quot; //名字可以自己取 参考1 参考2]]></content>
  </entry>
  <entry>
    <title><![CDATA[Markdown常用格式]]></title>
    <url>%2F2018%2F08%2F29%2FMarkdown%E5%B8%B8%E7%94%A8%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[标题在文本前面加上 # 即可，同理、你还可以增加二级标题、三级标题、四级标题、五级标题和六级标题，总共六级，只需要增加 # 即可。 注：# 和「一级标题」之间建议保留一个字符的空格。 列表在文字前面加上 - 就可以了。 也可以在文字前面加上 1. 2. 3。 注：-、1.和文本之间要保留一个字符的空格。 插入链接和图片插入链接使用 [显示文本](链接地址) 这样的语法即可。 插入图片只需要使用 ![](图片链接地址) 这样的语法即可。 注：插入图片的语法和链接的语法很像，只是前面多了一个 ！。 引用在希望引用的文字前面加上 &gt; 就好了。 注：&gt; 和文本之间要保留一个字符的空格。 粗体和斜体用两个 包含一段文本就是粗体的语法，用一个 包含一段文本就是斜体的语法。 代码引用需要引用代码时，如果引用的语句只有一段，不分行，可以用 ` 将语句包起来。 如果引用的语句为多行，可以将`置于这段代码的首行和末行。 表格使用 | 来分隔不同的单元格，使用 - 来分隔表头和其他行。 参考1 参考2 Markdown编辑器]]></content>
  </entry>
  <entry>
    <title><![CDATA[我的第一篇博客]]></title>
    <url>%2F2018%2F08%2F29%2F%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[我有一头小毛驴，可是我从来都不骑。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F08%2F29%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
